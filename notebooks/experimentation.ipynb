{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Retrieval Experiment Notebook\n",
    "\n",
    "In this notebook, we will use the [Beir](https://github.com/beir-cellar/beir) library to experiment with different information retrieval techniques. We will use the same dataset (XML-Coll-withSem). As we already have explored probabilistic models and vector space models, we will focus on neural models in this notebook. \n",
    "\n",
    "Read about the beir paper :\n",
    "[A Heterogeneous Benchmark for Zero-shot\n",
    "Evaluation of Information Retrieval Models](https://openreview.net/pdf?id=wCu6T5xFjeJ)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "Let's start by importing the libraries we need for this project. You can install any missing libraries using the requirements.txt file provided or by running the following command in your terminal:\n",
    "\n",
    "```bash\n",
    "make install\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "from time import time\n",
    "from beir import util, LoggingHandler\n",
    "from beir.retrieval import models\n",
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "from beir.retrieval.search.dense import DenseRetrievalExactSearch as DRES\n",
    "\n",
    "import logging\n",
    "\n",
    "import jsonlines\n",
    "import zipfile\n",
    "import io\n",
    "import re\n",
    "import os\n",
    "\n",
    "from textprocessor import CustomTextProcessorNoStem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "As we want to use our own dataset with Beir, we need to convert it to the format that Beir expects. \n",
    "We will also use our ``textprocessor`` module to preprocess the data before feeding it to the models. We also transformed the queries file to the format expected by Beir manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "textprocessor = CustomTextProcessorNoStem()\n",
    "\n",
    "def parse_xml_to_json(filename, lines):\n",
    "    \"\"\"\n",
    "    Parses XML content into a JSON format.\n",
    "\n",
    "    Args:\n",
    "        filename (str): The name of the file being parsed.\n",
    "        lines (list): The lines of content to be parsed.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the parsed data in JSON format.\n",
    "    \"\"\"\n",
    "    docno = filename.split('/')[-1].split('.')[0]\n",
    "    \n",
    "    content = ' '.join(lines)\n",
    "    content = re.sub('&[^;]+;', ' ', content)\n",
    "    \n",
    "    text = re.sub('<[^>]+>', '', content)\n",
    "    tokens = textprocessor.pre_processing(text)\n",
    "     \n",
    "    return {docno: {'title': \"\", 'text': ' '.join(tokens)}}\n",
    "    \n",
    "    \n",
    "def parse_collection(file):\n",
    "    \"\"\"\n",
    "    Parses a collection of XML files into a JSON format.\n",
    "\n",
    "    Args:\n",
    "        file (str): The path to the collection file.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the parsed data in JSON format.\n",
    "    \"\"\"\n",
    "    parsed_data = {}\n",
    "    with zipfile.ZipFile(file, 'r') as zip_file:\n",
    "        for filename in zip_file.namelist():\n",
    "            with zip_file.open(filename) as binary_file:\n",
    "                with io.TextIOWrapper(binary_file, encoding='utf-8') as f:\n",
    "                    parsed_data.update(parse_xml_to_json(filename, f.readlines()))\n",
    "                    \n",
    "    return parsed_data\n",
    "                    \n",
    "def save_parsed_collection(parsed_data, output_file):\n",
    "    \"\"\"\n",
    "    Saves the parsed collection data to a JSON file.\n",
    "\n",
    "    Args:\n",
    "        parsed_data (dict): The parsed data to be saved.\n",
    "        output_file (str): The path to the output file.\n",
    "    \"\"\"\n",
    "    with jsonlines.open(output_file, 'w') as writer:\n",
    "        for docno, data in parsed_data.items():\n",
    "            writer.write({'_id': docno, 'title': data['title'], 'text': data['text']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CHOOSE DATASET :** Change the dataset name in the following cell to use a different dataset.\n",
    "if the dataset has not already been formatted, you should uncomment the following cell to format it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'small'\n",
    "# parsed_data = parse_collection('../lib/data/practice_05/' + dataset_name + '.zip') \n",
    "# save_parsed_collection(parsed_data,'./data/' + dataset_name + '.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_path = \"./data/\" + dataset_name + \".jsonl\"\n",
    "query_path = \"./data/queries.jsonl\"\n",
    "qrels_path = \"./data/qrl.tsv\" # Mandatory for validation evaluation only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beir Setup\n",
    "Now that we have our data ready, we can start using Beir. We will define a logger and start by loading the dataset. And define some useful class to simplify the use of the different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-30 23:27:08 - Loading Corpus...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 647.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-30 23:27:08 - Loaded 10 Documents.\n",
      "2023-12-30 23:27:08 - Doc Example: {'text': 'algorithms calculating variance lese statistical algorithms statistical deviation dispersion articles example pseudocode algorithms calculating variance play major role statistical computing key problem design good algorithms problem formulas variance involve sums squares lead numerical instability well arithmetic overflow dealing large values nave algorithm formula calculating variance entire population size displaystylefrac sum_ sum_ x_i formula calculating unbiased estimate population variance finite sample observations displaystylefrac sum_ sum_ x_i naive algorithm calculate estimated variance pseudocode sum sum_sqr foreach data sum sum sum_sqr sum_sqr sumn variance sum_sqr sum algorithm easily adapted compute variance finite population simply divide minus sum_sqr sum numbers precision result inherent precision floatingpoint arithmetic perform computation bad variance small relative sum numbers ii twopass algorithm alternate approach formula variance pseudocode foreach data foreach data variance algorithm numerically reliable nave algorithm large sets data worse data close precisely equal simple algorithms ii depend inordinately ordering data poor large data sets repeated roundoff error accumulation sums techniques compensated summation combat error degree iia compensated variant compensatedsummation version algorithm reads foreach data sumc foreach data sumc sumc variance iii online algorithm compute variance single pass inspecting x_i example data collected storage values costs memory access dominate computation online algorithm recurrence relation required quantities required statistics calculated numerically stable fashion formulas update estimated variance sequence additional element x_ mathrm denotes estimate population sample estimate population variance estimate sample variance number elements sequence addition m_ mathrm frac m_ mathrm x_ mathrm m_ mathrm frac x_ mathrm m_ mathrm mathrm frac mathrm x_ mathrm m_ mathrm x_ mathrm m_ mathrm mathrm gt mathrm frac mathrm x_ mathrm m_ mathrm x_ mathrm m_ mathrm turns suitable quantity updating sum squares differences current sum_ x_i denoted m_mathrm m_mathrm x_mathrm m_mathrm x_mathrm m_mathrm frac frac numerically stable algorithm computes algorithm cites foreach data delta deltan delta expression variance_n variance algorithm prone loss precision massive cancellation efficient division operation inside loop robust twopass algorithm computing variance compute subtract estimate algorithm residuals convenient form allows calculate standard deviation explicitly calculate number elements sequence addition element mathrm frac mathrm frac left x_text m_text right iv weighted incremental algorithm observations weighted west suggests incremental algorithm foreach data sumweight weight temp weight sumweight sumweight weight xmean temp xmean weight temp sumweight temp variance sumweight sample population omit parallel algorithm chan note online algorithm iii special case algorithm works partition sample sets xa xb delta mb ma mx ma deltacdotfrac nb nx na nb nx example multiple processing units assigned discrete parts input higherorder statistics extends chan formulae calculating third fourth central moments needed example estimating skewness kurtosis na nb na nb nx nx begin align na nb left na na nb nb nx na nb nx nx end align m_k sums powers differences sigma overline skewness frac sqrt kurtosis frac incremental case ie simplifies delta frac delta frac frac frac frac frac frac preserving delta division operation needed higherorder statistics calculated incremental cost example assume floating point operations standard ieee doubleprecision arithmetic consider sample infinite population based sample estimated population unbiased estimate population variance algorithm algorithm ii compute values correctly consider sample rise estimated variance sample algorithm ii computes variance estimate correctly algorithm returns loss precision tolerable viewed minor flaw algorithm easy find data reveal major flaw naive algorithm sample estimated population variance computed correctly algorithm ii naive algorithm computes minus serious problem algorithm variance definition negative computational formula variance references donald knuth art computer programming volume seminumerical algorithms edn boston addisonwesley welford note method calculating corrected sums squares products technometrics west communications acm updating variance estimates improved method chan tony golub gene leveque randall updating formulae pairwise algorithm computing sample variances technical report department computer science stanford university terriberry timothy computing higherorder moments online external links eric weisstein sample variance computation mathworld', 'title': ''}\n",
      "2023-12-30 23:27:08 - Loading Queries...\n",
      "2023-12-30 23:27:08 - Loaded 7 Queries.\n",
      "2023-12-30 23:27:08 - Query Example: olive oil health benefit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# define a logger and capture results\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.INFO,\n",
    "                    handlers=[LoggingHandler()])\n",
    "\n",
    "# load our dataset\n",
    "corpus, queries, qrels = GenericDataLoader(\n",
    "    corpus_file=corpus_path, \n",
    "    query_file=query_path, \n",
    "    qrels_file=qrels_path).load_custom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BEIRModelWrapper:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.retriever = None\n",
    "        self.model_name = None\n",
    "        self.score_function = \"dot\"\n",
    "\n",
    "    def get_results(self, corpus, queries):\n",
    "        results = self.retriever.retrieve(corpus, queries)\n",
    "        return results\n",
    "    \n",
    "    def evaluate(self, qrels, results):\n",
    "        return self.retriever.evaluate(qrels, results, self.retriever.k_values)\n",
    "\n",
    "    def get_model_name(self):\n",
    "        return self.model_name\n",
    "\n",
    "class SentenceBERTModelWrapper(BEIRModelWrapper):\n",
    "    def __init__(self, batch_size=256, corpus_chunk_size=512*9999):\n",
    "        super().__init__()\n",
    "        self.model_path = \"msmarco-distilbert-base-tas-b\"\n",
    "        self.model = DRES(models.SentenceBERT(self.model_path), batch_size=batch_size, corpus_chunk_size=corpus_chunk_size)\n",
    "        self.retriever = EvaluateRetrieval(self.model, score_function=self.score_function)\n",
    "        self.model_name = f\"SBERT_{self.model_path.replace('-', '_')}\"\n",
    "        \n",
    "class ANCEModelWrapper(BEIRModelWrapper):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model_path = \"msmarco-roberta-base-ance-firstp\"\n",
    "        self.model = DRES(models.SentenceBERT(self.model_path))\n",
    "        self.retriever = EvaluateRetrieval(self.model, score_function=\"dot\")\n",
    "        self.model_name = f\"ANCE_{self.model_path.replace('-', '_')}\"\n",
    "    \n",
    "# ###############################################\n",
    "# Below Models need GPU support\n",
    "# ###############################################\n",
    "\n",
    "class DPRModelWrapper(BEIRModelWrapper):\n",
    "    def __init__(self, batch_size=128):\n",
    "        super().__init__()\n",
    "        self.question_encoder = \"facebook/dpr-question_encoder-multiset-base\"\n",
    "        self.ctx_encoder = \"facebook/dpr-ctx_encoder-multiset-base\"\n",
    "        self.model = DRES(models.DPR((self.question_encoder, self.ctx_encoder), batch_size=batch_size))\n",
    "        \n",
    "        self.retriever = EvaluateRetrieval(self.model, score_function=self.score_function)\n",
    "        self.model_name = f\"DPR_dpr_ctx_encoder_multiset_base_dpr_ctx_encoder_multiset_base_\"\n",
    "        \n",
    "class UseQAModelWrapper(BEIRModelWrapper):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model_path = \"https://tfhub.dev/google/universal-sentence-encoder-qa/3\"\n",
    "        self.model = DRES(models.UseQA(self.model_path))\n",
    "        self.retriever = EvaluateRetrieval(self.model, score_function=\"dot\")\n",
    "        \n",
    "        self.model_name = f\"USEQA_universal_sentence_encoder_qa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-30 23:29:31 - Load pretrained SentenceTransformer: msmarco-distilbert-base-tas-b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-30 23:29:36 - Use pytorch device: cpu\n"
     ]
    }
   ],
   "source": [
    "model_wrapper = SentenceBERTModelWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-30 23:17:27 - Encoding Queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-30 23:17:29 - Sorting Corpus by document length (Longest first)...\n",
      "2023-12-30 23:17:29 - Encoding Corpus in batches... Warning: This might take a while!\n",
      "2023-12-30 23:17:29 - Scoring Function: Dot Product (dot)\n",
      "2023-12-30 23:17:29 - Encoding Batch 1/1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:14<00:00, 14.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to retrieve: 17.25 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "results = model_wrapper.get_results(corpus, queries)\n",
    "end_time = time()\n",
    "\n",
    "print(\"Time taken to retrieve: {:.2f} seconds\".format(end_time - start_time))\n",
    "\n",
    "# logging.info(\"Retriever evaluation for k in: {}\".format(model_wrapper.retriever.k_values))\n",
    "# ndcg, _map, recall, precision = model_wrapper.evaluate(qrels, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Generation\n",
    "\n",
    "Now that we have the results, we can generate the run files that will be used to evaluate the models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_OUTPUT_FOLDER = \"../docs/resources/runs/\"\n",
    "\n",
    "def format_results(results):\n",
    "    res = []\n",
    "    for query_id, score in results.items():\n",
    "        for doc_id, score in score.items():\n",
    "            res.append((query_id, doc_id, score))\n",
    "            \n",
    "    # lets group in different list the results for each query\n",
    "    res_grouped = {}\n",
    "    for query_id, doc_id, score in res:\n",
    "        if query_id not in res_grouped:\n",
    "            res_grouped[query_id] = []\n",
    "        res_grouped[query_id].append((doc_id, score))\n",
    "\n",
    "    # lets sort the results for each query by score\n",
    "    for query_id in res_grouped:\n",
    "        res_grouped[query_id] = sorted(res_grouped[query_id], key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "    return res_grouped\n",
    "\n",
    "def get_run_id(folder_path=RUN_OUTPUT_FOLDER):\n",
    "    files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "    return len(files) + 1\n",
    "\n",
    "def display_top_k_results(results, k=10):\n",
    "    for query_id, doc_ids in results.items():\n",
    "        print(f\"Query {query_id}:\")\n",
    "        for i, (doc_id, score) in enumerate(doc_ids[:k]):\n",
    "            print(f\"\\t{i+1}. {doc_id} ({score})\")\n",
    "        print()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_name = \"BengezzouIdrissMezianeGhilas\"\n",
    "run_id = get_run_id()\n",
    "processing = textprocessor.get_text_processor_name()\n",
    "run_file = f\"{RUN_OUTPUT_FOLDER}{team_name}_{run_id}_{model_wrapper.get_model_name()}_{processing}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 2009011:\n",
      "\t1. 1064 (703.6972045898438)\n",
      "\t2. 1134 (702.343505859375)\n",
      "\t3. 612 (702.04296875)\n",
      "\t4. 753 (701.8960571289062)\n",
      "\t5. 627 (701.69287109375)\n",
      "\t6. 1164 (701.625244140625)\n",
      "\t7. 775 (701.3036499023438)\n",
      "\t8. 1063 (700.8485107421875)\n",
      "\t9. 780 (699.796142578125)\n",
      "\t10. 717 (698.7045288085938)\n",
      "\n",
      "Query 2009036:\n",
      "\t1. 753 (706.2047119140625)\n",
      "\t2. 612 (704.6282958984375)\n",
      "\t3. 627 (703.4949951171875)\n",
      "\t4. 775 (702.9257202148438)\n",
      "\t5. 1134 (702.78515625)\n",
      "\t6. 1164 (702.0452880859375)\n",
      "\t7. 1063 (701.9610595703125)\n",
      "\t8. 1064 (701.3392944335938)\n",
      "\t9. 780 (699.7847900390625)\n",
      "\t10. 717 (698.1004638671875)\n",
      "\n",
      "Query 2009067:\n",
      "\t1. 775 (707.5659790039062)\n",
      "\t2. 612 (706.60302734375)\n",
      "\t3. 1134 (706.4557495117188)\n",
      "\t4. 1164 (705.624267578125)\n",
      "\t5. 1063 (705.209228515625)\n",
      "\t6. 627 (705.1932983398438)\n",
      "\t7. 1064 (703.7508544921875)\n",
      "\t8. 753 (701.9403686523438)\n",
      "\t9. 780 (701.7125244140625)\n",
      "\t10. 717 (699.7239990234375)\n",
      "\n",
      "Query 2009073:\n",
      "\t1. 1134 (705.3028564453125)\n",
      "\t2. 1063 (704.0633544921875)\n",
      "\t3. 612 (703.7564697265625)\n",
      "\t4. 775 (703.6566162109375)\n",
      "\t5. 627 (702.8421020507812)\n",
      "\t6. 1164 (702.302001953125)\n",
      "\t7. 753 (701.2151489257812)\n",
      "\t8. 1064 (701.1204223632812)\n",
      "\t9. 780 (699.4462890625)\n",
      "\t10. 717 (696.8572998046875)\n",
      "\n",
      "Query 2009074:\n",
      "\t1. 1063 (707.9261474609375)\n",
      "\t2. 775 (706.1871948242188)\n",
      "\t3. 612 (705.8320922851562)\n",
      "\t4. 1134 (704.66455078125)\n",
      "\t5. 1164 (702.765869140625)\n",
      "\t6. 627 (702.5025634765625)\n",
      "\t7. 753 (701.6182250976562)\n",
      "\t8. 1064 (701.4148559570312)\n",
      "\t9. 780 (699.2677612304688)\n",
      "\t10. 717 (697.1964111328125)\n",
      "\n",
      "Query 2009078:\n",
      "\t1. 775 (705.4638671875)\n",
      "\t2. 1164 (704.40625)\n",
      "\t3. 1063 (704.138427734375)\n",
      "\t4. 612 (702.3310546875)\n",
      "\t5. 1134 (701.8921508789062)\n",
      "\t6. 627 (699.5718994140625)\n",
      "\t7. 1064 (699.4386596679688)\n",
      "\t8. 753 (698.3189086914062)\n",
      "\t9. 780 (696.3499755859375)\n",
      "\t10. 717 (695.7802734375)\n",
      "\n",
      "Query 2009085:\n",
      "\t1. 775 (704.2633666992188)\n",
      "\t2. 612 (703.2470703125)\n",
      "\t3. 1134 (702.4921875)\n",
      "\t4. 1164 (702.424560546875)\n",
      "\t5. 1063 (702.0982666015625)\n",
      "\t6. 753 (701.2050170898438)\n",
      "\t7. 627 (700.8327026367188)\n",
      "\t8. 1064 (698.7427368164062)\n",
      "\t9. 780 (698.03662109375)\n",
      "\t10. 717 (697.7295532226562)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "formated_results = format_results(results)\n",
    "# display_top_k_results(formated_results)\n",
    "\n",
    "with open(run_file, \"w\") as f_out:\n",
    "    for query_id in formated_results:\n",
    "        for rank, (doc_id, score) in enumerate(formated_results[query_id]):\n",
    "            f_out.write(\"{} Q0 {} {} {} BengezzouIdrissMezianeGhilas /article[1]\\n\".format(query_id, doc_id, rank+1, score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
