{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Retrieval Experiment Notebook\n",
    "\n",
    "In this notebook, we will use the [Beir](https://github.com/beir-cellar/beir) library to experiment with different information retrieval techniques. We will use the same dataset (XML-Coll-withSem). As we already have explored probabilistic models and vector space models, we will focus on neural models in this notebook.\n",
    "\n",
    "Read about the beir paper :\n",
    "[A Heterogeneous Benchmark for Zero-shot\n",
    "Evaluation of Information Retrieval Models](https://openreview.net/pdf?id=wCu6T5xFjeJ)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "Let's start by importing the libraries we need for this project. You can install any missing libraries using the requirements.txt file provided or by running the following command in your terminal:\n",
    "\n",
    "```bash\n",
    "make install\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marwan/.local/lib/python3.10/site-packages/beir/datasets/data_loader.py:2: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "from time import time\n",
    "from beir import util, LoggingHandler\n",
    "from beir.retrieval import models\n",
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "from beir.retrieval.search.dense import DenseRetrievalExactSearch as DRES\n",
    "\n",
    "import logging\n",
    "\n",
    "from tqdm import tqdm\n",
    "import jsonlines\n",
    "import zipfile\n",
    "import io\n",
    "import re\n",
    "import os\n",
    "\n",
    "from textprocessor import CustomTextProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "As we want to use our own dataset with Beir, we need to convert it to the format that Beir expects.\n",
    "We will also use our `textprocessor` module to preprocess the data before feeding it to the models. We also transformed the queries file to the format expected by Beir manually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "textprocessor = CustomTextProcessor()\n",
    "\n",
    "\n",
    "def parse_xml_to_json(filename, lines):\n",
    "    \"\"\"\n",
    "    Parses XML content into a JSON format.\n",
    "\n",
    "    Args:\n",
    "        filename (str): The name of the file being parsed.\n",
    "        lines (list): The lines of content to be parsed.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the parsed data in JSON format.\n",
    "    \"\"\"\n",
    "    docno = filename.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "    content = \" \".join(lines)\n",
    "    content = re.sub(\"&[^;]+;\", \" \", content)\n",
    "\n",
    "    text = re.sub(\"<[^>]+>\", \" \", content)\n",
    "    tokens = textprocessor.pre_processing(text)\n",
    "\n",
    "    return {docno: {\"title\": \"\", \"text\": \" \".join(tokens)}}\n",
    "\n",
    "\n",
    "def parse_collection(file):\n",
    "    \"\"\"\n",
    "    Parses a collection of XML files into a JSON format.\n",
    "\n",
    "    Args:\n",
    "        file (str): The path to the collection file.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the parsed data in JSON format.\n",
    "    \"\"\"\n",
    "    parsed_data = {}\n",
    "    with zipfile.ZipFile(file, \"r\") as zip_file:\n",
    "        for filename in zip_file.namelist():\n",
    "            with zip_file.open(filename) as binary_file:\n",
    "                with io.TextIOWrapper(binary_file, encoding=\"utf-8\") as f:\n",
    "                    parsed_data.update(parse_xml_to_json(filename, f.readlines()))\n",
    "\n",
    "    return parsed_data\n",
    "\n",
    "\n",
    "def save_parsed_collection(parsed_data, output_file):\n",
    "    \"\"\"\n",
    "    Saves the parsed collection data to a JSON file.\n",
    "\n",
    "    Args:\n",
    "        parsed_data (dict): The parsed data to be saved.\n",
    "        output_file (str): The path to the output file.\n",
    "    \"\"\"\n",
    "    with jsonlines.open(output_file, \"w\") as writer:\n",
    "        for docno, data in parsed_data.items():\n",
    "            writer.write({\"_id\": docno, \"title\": data[\"title\"], \"text\": data[\"text\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CHOOSE DATASET :** Change the dataset name in the following cell to use a different dataset.\n",
    "if the dataset has not already been formatted, you should uncomment the following cell to format it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"XML-Coll-withSem\"\n",
    "\n",
    "dataset_folder = \"../lib/processed_data/ir_machine_learning/\"\n",
    "os.makedirs(dataset_folder, exist_ok=True)\n",
    "\n",
    "# ! Uncomment to parse the collection\n",
    "# parsed_data = parse_collection('../lib/data/practice_05/' + dataset_name + '.zip')\n",
    "# save_parsed_collection(parsed_data, dataset_folder + dataset_name + '.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_path = dataset_folder + dataset_name + \".jsonl\"\n",
    "query_path = dataset_folder + \"queries.jsonl\"\n",
    "qrels_path = (\n",
    "    dataset_folder + \"qrl.tsv\"\n",
    ")  # Mandatory for validation evaluation only (not used)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beir Setup\n",
    "\n",
    "Now that we have our data ready, we can start using Beir. We will define a logger and start by loading the dataset. And define some useful class to simplify the use of the different models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-09 02:36:05 - Loading Corpus...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9804 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9804/9804 [00:00<00:00, 73639.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-09 02:36:05 - Loaded 9804 Documents.\n",
      "2024-01-09 02:36:05 - Doc Example: {'text': 'gottschalk benson eastlaw unit patent case law flag suprem court articl law computerrel patent case law unit suprem court case gottschalk benson suprem court unit argu octob decid novemb full case gottschalk act commission patent benson citat lexi bna prior histori certiorari unit court custom patent appeal subsequ histori diamond diehr diamond chakrabarti hold respond method convert numer inform decim number pure binari number program convent generalpurpos digit comput seri mathemat calcul mental step constitut patent process mean patent usc court membership chief justic warren burger associ justic william dougla william brennan potter stewart byron white thurgood marshal harri blackmun lewi powel william rehnquist case opinion major burger brennan white marshal rehnquist stewart blackmun powel consider decis case law appli patent gottschalk benson unit suprem court case rule process involv numer algorithm patent patent wholli preempt mathemat formula practic patent algorithm court decis preclud patent program servic comput hold case argu octob decid novemb prior histori case revolv applic patent method convert decim bcd numer pure binari numer gener purpos digit comput patent examin unit patent trademark offic reject patent applic direct mathemat express pure mathemat express held unpatent earlier patent law mackay radio corp applic appeal board patent appeal interfer board affirm examin reject applic appeal court custom patent appeal court revers board final commission patent trademark file petit writ certiorari suprem court case law applic case patent question claim process law court held claim limit type programm digit comput method carri mental claim effect preclud method current futur field claim direct algorithm patent impact decis confirm softwar directli patent patent attorney patent protect softwar invent claim algorithm combin comput carri algorithm technic claim machin held patent boundari comput implement process pure abstract idea patent practic process patent matter debat patent offic suprem court clear subject matter exclud scope repres law natur natur phenomena abstract idea note invent discov process machin manufactur composit matter improv patent therefor subject condit requir titl definit process term process process art method includ process machin manufactur composit matter materi list unit suprem court case volum refer promot progress art report presid commiss patent system cite gottschalk benson mathemat algorithm patent manual patent examin procedur', 'title': ''}\n",
      "2024-01-09 02:36:05 - Loading Queries...\n",
      "2024-01-09 02:36:05 - Loaded 7 Queries.\n",
      "2024-01-09 02:36:05 - Query Example: olive oil health benefit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# define a logger and capture results\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    "    handlers=[LoggingHandler()],\n",
    ")\n",
    "\n",
    "# load our dataset\n",
    "corpus, queries, qrels = GenericDataLoader(\n",
    "    corpus_file=corpus_path, query_file=query_path, qrels_file=qrels_path\n",
    ").load_custom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BEIRModelWrapper:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.retriever = None\n",
    "        self.model_name = None\n",
    "        self.score_function = \"dot\"\n",
    "        self.k_values = [1, 3, 5, 10, 100, 1000, 1500]\n",
    "\n",
    "    def get_results(self, corpus, queries):\n",
    "        print(f\"Retrieving top-{self.retriever.top_k} results ...\")\n",
    "        self.retriever.top_k = max(self.k_values)\n",
    "        results = self.retriever.retrieve(corpus, queries)\n",
    "        return results\n",
    "\n",
    "    def evaluate(self, qrels, results):\n",
    "        return self.retriever.evaluate(qrels, results, self.retriever.k_values)\n",
    "\n",
    "    def get_model_name(self):\n",
    "        return self.model_name\n",
    "\n",
    "\n",
    "class SentenceBERTModelWrapper(BEIRModelWrapper):\n",
    "    def __init__(self, batch_size=32, corpus_chunk_size=64 * 9999):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model_path = \"msmarco-distilbert-base-tas-b\"\n",
    "        self.model = DRES(\n",
    "            models.SentenceBERT(self.model_path),\n",
    "            batch_size=batch_size,\n",
    "            corpus_chunk_size=corpus_chunk_size,\n",
    "        )\n",
    "\n",
    "        self.score_function = \"cos_sim\"\n",
    "        print(f\"k_values: {self.k_values}\")\n",
    "        self.retriever = EvaluateRetrieval(\n",
    "            self.model, score_function=self.score_function, k_values=self.k_values\n",
    "        )\n",
    "        \n",
    "        print(\"Retriever top_k: \", self.retriever.top_k)\n",
    "        self.model_name = f\"SBERT_{self.model_path.replace('-', '_')}\"\n",
    "\n",
    "\n",
    "class ANCEModelWrapper(BEIRModelWrapper):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model_path = \"msmarco-roberta-base-ance-firstp\"\n",
    "        self.model = DRES(models.SentenceBERT(self.model_path))\n",
    "        self.retriever = EvaluateRetrieval(\n",
    "            self.model, score_function=\"dot\", k_values=self.k_values\n",
    "        )\n",
    "        self.model_name = f\"ANCE_{self.model_path.replace('-', '_')}\"\n",
    "\n",
    "\n",
    "# ###############################################\n",
    "# Below Models need GPU support\n",
    "# ###############################################\n",
    "\n",
    "\n",
    "class DPRModelWrapper(BEIRModelWrapper):\n",
    "    def __init__(self, batch_size=128):\n",
    "        super().__init__()\n",
    "        self.question_encoder = \"facebook/dpr-question_encoder-multiset-base\"\n",
    "        self.ctx_encoder = \"facebook/dpr-ctx_encoder-multiset-base\"\n",
    "        self.model = DRES(\n",
    "            models.DPR((self.question_encoder, self.ctx_encoder), batch_size=batch_size)\n",
    "        )\n",
    "\n",
    "        self.retriever = EvaluateRetrieval(\n",
    "            self.model, score_function=self.score_function, k_values=self.k_values\n",
    "        )\n",
    "        self.model_name = (\n",
    "            f\"DPR_dpr_ctx_encoder_multiset_base_dpr_ctx_encoder_multiset_base\"\n",
    "        )\n",
    "\n",
    "\n",
    "class UseQAModelWrapper(BEIRModelWrapper):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model_path = \"https://tfhub.dev/google/universal-sentence-encoder-qa/3\"\n",
    "        self.model = DRES(models.UseQA(self.model_path))\n",
    "        self.retriever = EvaluateRetrieval(\n",
    "            self.model, score_function=\"dot\", k_values=self.k_values\n",
    "        )\n",
    "\n",
    "        self.model_name = f\"USEQA_universal_sentence_encoder_qa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-09 02:36:40.679917: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-09 02:36:40.679973: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-09 02:36:40.739100: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-09 02:36:40.868550: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-09 02:36:42.133881: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/marwan/Github/information-retrieval/notebooks/IR_systems_machine_learning.ipynb Cell 12\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/marwan/Github/information-retrieval/notebooks/IR_systems_machine_learning.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/marwan/Github/information-retrieval/notebooks/IR_systems_machine_learning.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m model_wrapper \u001b[39m=\u001b[39m UseQAModelWrapper()\n",
      "\u001b[1;32m/home/marwan/Github/information-retrieval/notebooks/IR_systems_machine_learning.ipynb Cell 12\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/marwan/Github/information-retrieval/notebooks/IR_systems_machine_learning.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=77'>78</a>\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/marwan/Github/information-retrieval/notebooks/IR_systems_machine_learning.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=78'>79</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhttps://tfhub.dev/google/universal-sentence-encoder-qa/3\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/marwan/Github/information-retrieval/notebooks/IR_systems_machine_learning.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=79'>80</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m DRES(models\u001b[39m.\u001b[39;49mUseQA(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_path))\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/marwan/Github/information-retrieval/notebooks/IR_systems_machine_learning.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=80'>81</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretriever \u001b[39m=\u001b[39m EvaluateRetrieval(\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/marwan/Github/information-retrieval/notebooks/IR_systems_machine_learning.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=81'>82</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, score_function\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdot\u001b[39m\u001b[39m\"\u001b[39m, k_values\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk_values\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/marwan/Github/information-retrieval/notebooks/IR_systems_machine_learning.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=82'>83</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/marwan/Github/information-retrieval/notebooks/IR_systems_machine_learning.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=84'>85</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_name \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUSEQA_universal_sentence_encoder_qa\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/beir/retrieval/models/use_qa.py:15\u001b[0m, in \u001b[0;36mUseQA.__init__\u001b[0;34m(self, hub_url, **kwargs)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, hub_url\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 15\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minitialisation()\n\u001b[1;32m     16\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m hub\u001b[39m.\u001b[39mload(hub_url)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/beir/retrieval/models/use_qa.py:21\u001b[0m, in \u001b[0;36mUseQA.initialisation\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minitialisation\u001b[39m():\n\u001b[1;32m     20\u001b[0m     \u001b[39m# limiting tensorflow gpu-memory if used\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     gpus \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mlist_physical_devices(\u001b[39m'\u001b[39m\u001b[39mGPU\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     22\u001b[0m     \u001b[39mif\u001b[39;00m gpus:\n\u001b[1;32m     23\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "model_wrapper = UseQAModelWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving top-1500 results ...\n",
      "2024-01-08 23:39:44 - Encoding Queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-08 23:39:45 - Sorting Corpus by document length (Longest first)...\n",
      "2024-01-08 23:39:45 - Encoding Corpus in batches... Warning: This might take a while!\n",
      "2024-01-08 23:39:45 - Scoring Function: Dot Product (dot)\n",
      "2024-01-08 23:39:45 - Encoding Batch 1/1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [2:42:10<00:00, 126.37s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to retrieve: 9740.94 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "results = model_wrapper.get_results(corpus, queries)\n",
    "end_time = time()\n",
    "\n",
    "print(\"Time taken to retrieve: {:.2f} seconds\".format(end_time - start_time))\n",
    "\n",
    "# logging.info(\"Retriever evaluation for k in: {}\".format(model_wrapper.retriever.k_values))\n",
    "# ndcg, _map, recall, precision = model_wrapper.evaluate(qrels, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Generation\n",
    "\n",
    "Now that we have the results, we can generate the run files that will be used to evaluate the models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_OUTPUT_FOLDER = \"../docs/resources/runs/\"\n",
    "\n",
    "\n",
    "def format_results(results):\n",
    "    res = []\n",
    "    for query_id, score in results.items():\n",
    "        for doc_id, score in score.items():\n",
    "            res.append((query_id, doc_id, score))\n",
    "\n",
    "    # lets group in different list the results for each query\n",
    "    res_grouped = {}\n",
    "    for query_id, doc_id, score in res:\n",
    "        if query_id not in res_grouped:\n",
    "            res_grouped[query_id] = []\n",
    "        res_grouped[query_id].append((doc_id, score))\n",
    "\n",
    "    # lets sort the results for each query by score\n",
    "    for query_id in res_grouped:\n",
    "        res_grouped[query_id] = sorted(\n",
    "            res_grouped[query_id], key=lambda x: x[1], reverse=True\n",
    "        )\n",
    "\n",
    "    return res_grouped\n",
    "\n",
    "\n",
    "def get_run_id(folder_path=RUN_OUTPUT_FOLDER):\n",
    "    files = [\n",
    "        f\n",
    "        for f in os.listdir(folder_path)\n",
    "        if os.path.isfile(os.path.join(folder_path, f))\n",
    "    ]\n",
    "    return len(files) + 1\n",
    "\n",
    "\n",
    "def display_top_k_results(results, k=10):\n",
    "    for query_id, doc_ids in results.items():\n",
    "        print(f\"Query {query_id}:\")\n",
    "        for i, (doc_id, score) in enumerate(doc_ids[:k]):\n",
    "            print(f\"\\t{i+1}. {doc_id} ({score})\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_name = \"BengezzouIdrissMezianeGhilas\"\n",
    "run_id = get_run_id()\n",
    "processing = textprocessor.get_text_processor_name()\n",
    "granularity = \"article\"\n",
    "run_file = f\"{RUN_OUTPUT_FOLDER}{team_name}_{run_id}_{model_wrapper.get_model_name()}_{granularity}_{processing}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formated_results = format_results(results)\n",
    "# display_top_k_results(formated_results)\n",
    "\n",
    "with open(run_file, \"w\") as f_out:\n",
    "    for query_id in formated_results:\n",
    "        for rank, (doc_id, score) in enumerate(formated_results[query_id]):\n",
    "            f_out.write(\n",
    "                \"{} Q0 {} {} {} BengezzouIdrissMezianeGhilas /article[1]\\n\".format(\n",
    "                    query_id, doc_id, rank + 1, score\n",
    "                )\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
