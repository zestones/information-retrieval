{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Retrieval Experiment Notebook\n",
    "\n",
    "In this notebook, we will use the [Beir](https://github.com/beir-cellar/beir) library to experiment with different information retrieval techniques. We will use the same dataset (XML-Coll-withSem). As we already have explored probabilistic models and vector space models, we will focus on neural models in this notebook. \n",
    "\n",
    "Read about the beir paper :\n",
    "[A Heterogeneous Benchmark for Zero-shot\n",
    "Evaluation of Information Retrieval Models](https://openreview.net/pdf?id=wCu6T5xFjeJ)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "Let's start by importing the libraries we need for this project. You can install any missing libraries using the requirements.txt file provided or by running the following command in your terminal:\n",
    "\n",
    "```bash\n",
    "make install\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zestones/.local/lib/python3.10/site-packages/beir/datasets/data_loader.py:2: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "from time import time\n",
    "from beir import util, LoggingHandler\n",
    "from beir.retrieval import models\n",
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "from beir.retrieval.search.dense import DenseRetrievalExactSearch as DRES\n",
    "\n",
    "import logging\n",
    "\n",
    "import jsonlines\n",
    "import zipfile\n",
    "import io\n",
    "import re\n",
    "import os\n",
    "\n",
    "from textprocessor import CustomTextProcessorNoStem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "As we want to use our own dataset with Beir, we need to convert it to the format that Beir expects. \n",
    "We will also use our ``textprocessor`` module to preprocess the data before feeding it to the models. We also transformed the queries file to the format expected by Beir manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "textprocessor = CustomTextProcessorNoStem()\n",
    "\n",
    "def parse_xml_to_json(filename, lines):\n",
    "    \"\"\"\n",
    "    Parses XML content into a JSON format.\n",
    "\n",
    "    Args:\n",
    "        filename (str): The name of the file being parsed.\n",
    "        lines (list): The lines of content to be parsed.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the parsed data in JSON format.\n",
    "    \"\"\"\n",
    "    docno = filename.split('/')[-1].split('.')[0]\n",
    "    \n",
    "    content = ' '.join(lines)\n",
    "    content = re.sub('&[^;]+;', ' ', content)\n",
    "    \n",
    "    text = re.sub('<[^>]+>', '', content)\n",
    "    tokens = textprocessor.pre_processing(text)\n",
    "     \n",
    "    return {docno: {'title': \"\", 'text': ' '.join(tokens)}}\n",
    "    \n",
    "    \n",
    "def parse_collection(file):\n",
    "    \"\"\"\n",
    "    Parses a collection of XML files into a JSON format.\n",
    "\n",
    "    Args:\n",
    "        file (str): The path to the collection file.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the parsed data in JSON format.\n",
    "    \"\"\"\n",
    "    parsed_data = {}\n",
    "    with zipfile.ZipFile(file, 'r') as zip_file:\n",
    "        for filename in zip_file.namelist():\n",
    "            with zip_file.open(filename) as binary_file:\n",
    "                with io.TextIOWrapper(binary_file, encoding='utf-8') as f:\n",
    "                    parsed_data.update(parse_xml_to_json(filename, f.readlines()))\n",
    "                    \n",
    "    return parsed_data\n",
    "                    \n",
    "def save_parsed_collection(parsed_data, output_file):\n",
    "    \"\"\"\n",
    "    Saves the parsed collection data to a JSON file.\n",
    "\n",
    "    Args:\n",
    "        parsed_data (dict): The parsed data to be saved.\n",
    "        output_file (str): The path to the output file.\n",
    "    \"\"\"\n",
    "    with jsonlines.open(output_file, 'w') as writer:\n",
    "        for docno, data in parsed_data.items():\n",
    "            writer.write({'_id': docno, 'title': data['title'], 'text': data['text']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CHOOSE DATASET :** Change the dataset name in the following cell to use a different dataset.\n",
    "if the dataset has not already been formatted, you should uncomment the following cell to format it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'XML-Coll-withSem'\n",
    "\n",
    "# Uncomment to parse the collection\n",
    "# parsed_data = parse_collection('../lib/data/practice_05/' + dataset_name + '.zip') \n",
    "# save_parsed_collection(parsed_data,'./data/' + dataset_name + '.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_path = \"./data/\" + dataset_name + \".jsonl\"\n",
    "query_path = \"./data/queries.jsonl\"\n",
    "qrels_path = \"./data/qrl.tsv\" # Mandatory for validation evaluation only (not used)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beir Setup\n",
    "Now that we have our data ready, we can start using Beir. We will define a logger and start by loading the dataset. And define some useful class to simplify the use of the different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-31 03:17:25 - Loading Corpus...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9804/9804 [00:01<00:00, 8954.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-31 03:17:29 - Loaded 9804 Documents.\n",
      "2023-12-31 03:17:29 - Doc Example: {'text': 'gottschalk benson eastlaw united patent case law flagged us supreme court articles law computerrelated patent case law united supreme court cases gottschalk benson supreme court united argued october november full case gottschalk acting commissioner patents benson al citations us ct us lexis uspq bna prior history certiorari united court customs patent appeals subsequent history diamond diehr diamond chakrabarty holding respondents method converting numerical binarycoded decimal numbers pure binary numbers programming conventional generalpurpose digital computers series mathematical calculations mental steps constitute patentable process meaning patent usc court membership chief justice warren burger associate justices william douglas william brennan jr potter stewart byron white thurgood marshall harry blackmun lewis powell jr william rehnquist case opinions majority douglasjoined burger brennan white marshall rehnquiststewart blackmun powell consideration decision case laws applied patent gottschalk benson us united supreme court case ruled process involving numerical algorithm patentable patent wholly preempt mathematical formula practical patent algorithm court decision precludes patent program servicing computer hold case argued october decided november prior history case revolves application patent method converting binarycoded decimal bcd numerals pure binary numerals general purpose digital computer patent examiner united patent trademark office rejected patent application directed mathematical expression pure mathematical expressions held unpatentable earlier patent laws mackay co radio corp us applicant appealed board patent appeals interferences board affirmed examiner rejection applicant appealed court customs patent appeals court reversed board finally commissioner patents trademarks filed petition writ certiorari supreme court case law applicable case patent http question claimed process law court held claim limited type programmable digital computer method carried mentally claim effectively preclude method currently future field claim directed algorithm patentable impact decision confirming software directly patentable patent attorneysagents patent protection software inventions claiming algorithm combination computer carrying algorithm technically claiming machine held patentable boundary computer implemented process purely abstract idea patentable practical process patentable matter debate patent office supreme court clear subject matter excluded scope represents laws nature natural phenomena abstract ideas notes invents discovers process machine manufacture composition matter improvement patent therefor subject conditions requirements title definition process term process process art method includes process machine manufacture composition matter material http list united supreme court cases volume references promote progress arts report president commission patent system cited gottschalk benson mathematical algorithms patentability manual patent examining procedure', 'title': ''}\n",
      "2023-12-31 03:17:29 - Loading Queries...\n",
      "2023-12-31 03:17:29 - Loaded 7 Queries.\n",
      "2023-12-31 03:17:29 - Query Example: olive oil health benefit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# define a logger and capture results\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.INFO,\n",
    "                    handlers=[LoggingHandler()])\n",
    "\n",
    "# load our dataset\n",
    "corpus, queries, qrels = GenericDataLoader(\n",
    "    corpus_file=corpus_path, \n",
    "    query_file=query_path, \n",
    "    qrels_file=qrels_path).load_custom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BEIRModelWrapper:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.retriever = None\n",
    "        self.model_name = None\n",
    "        self.score_function = \"dot\"\n",
    "        self.k_values = [1, 3, 5, 10, 100, 1000, 1500]\n",
    "\n",
    "    def get_results(self, corpus, queries):\n",
    "        results = self.retriever.retrieve(corpus, queries)\n",
    "        return results\n",
    "    \n",
    "    def evaluate(self, qrels, results):\n",
    "        return self.retriever.evaluate(qrels, results, self.retriever.k_values)\n",
    "\n",
    "    def get_model_name(self):\n",
    "        return self.model_name\n",
    "\n",
    "class SentenceBERTModelWrapper(BEIRModelWrapper):\n",
    "    def __init__(self, batch_size=32, corpus_chunk_size=16*9999):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model_path = \"msmarco-distilbert-base-tas-b\"\n",
    "        self.model = DRES(models.SentenceBERT(self.model_path), batch_size=batch_size, corpus_chunk_size=corpus_chunk_size)\n",
    "        \n",
    "        self.score_function = \"cos_sim\"\n",
    "        self.retriever = EvaluateRetrieval(self.model, score_function=self.score_function, k_values=self.k_values)\n",
    "        \n",
    "        self.model_name = f\"SBERT_{self.model_path.replace('-', '_')}\"\n",
    "        \n",
    "class ANCEModelWrapper(BEIRModelWrapper):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model_path = \"msmarco-roberta-base-ance-firstp\"\n",
    "        self.model = DRES(models.SentenceBERT(self.model_path))\n",
    "        self.retriever = EvaluateRetrieval(self.model, score_function=\"dot\", k_values=self.k_values)\n",
    "        self.model_name = f\"ANCE_{self.model_path.replace('-', '_')}\"\n",
    "    \n",
    "# ###############################################\n",
    "# Below Models need GPU support\n",
    "# ###############################################\n",
    "\n",
    "class DPRModelWrapper(BEIRModelWrapper):\n",
    "    def __init__(self, batch_size=128):\n",
    "        super().__init__()\n",
    "        self.question_encoder = \"facebook/dpr-question_encoder-multiset-base\"\n",
    "        self.ctx_encoder = \"facebook/dpr-ctx_encoder-multiset-base\"\n",
    "        self.model = DRES(models.DPR((self.question_encoder, self.ctx_encoder), batch_size=batch_size))\n",
    "        \n",
    "        self.retriever = EvaluateRetrieval(self.model, score_function=self.score_function, k_values=self.k_values)\n",
    "        self.model_name = f\"DPR_dpr_ctx_encoder_multiset_base_dpr_ctx_encoder_multiset_base\"\n",
    "        \n",
    "class UseQAModelWrapper(BEIRModelWrapper):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model_path = \"https://tfhub.dev/google/universal-sentence-encoder-qa/3\"\n",
    "        self.model = DRES(models.UseQA(self.model_path))\n",
    "        self.retriever = EvaluateRetrieval(self.model, score_function=\"dot\", k_values=self.k_values)\n",
    "        \n",
    "        self.model_name = f\"USEQA_universal_sentence_encoder_qa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-31 03:17:29 - Load pretrained SentenceTransformer: msmarco-distilbert-base-tas-b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-31 03:17:30 - Use pytorch device: cpu\n"
     ]
    }
   ],
   "source": [
    "model_wrapper = SentenceBERTModelWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-31 03:17:30 - Encoding Queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-31 03:17:31 - Sorting Corpus by document length (Longest first)...\n",
      "2023-12-31 03:17:31 - Encoding Corpus in batches... Warning: This might take a while!\n",
      "2023-12-31 03:17:31 - Scoring Function: Cosine Similarity (cos_sim)\n",
      "2023-12-31 03:17:31 - Encoding Batch 1/1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches:  20%|█▉        | 60/307 [22:46<1:51:54, 27.19s/it]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "results = model_wrapper.get_results(corpus, queries)\n",
    "end_time = time()\n",
    "\n",
    "print(\"Time taken to retrieve: {:.2f} seconds\".format(end_time - start_time))\n",
    "\n",
    "# logging.info(\"Retriever evaluation for k in: {}\".format(model_wrapper.retriever.k_values))\n",
    "# ndcg, _map, recall, precision = model_wrapper.evaluate(qrels, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Generation\n",
    "\n",
    "Now that we have the results, we can generate the run files that will be used to evaluate the models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_OUTPUT_FOLDER = \"../docs/resources/runs/\"\n",
    "\n",
    "def format_results(results):\n",
    "    res = []\n",
    "    for query_id, score in results.items():\n",
    "        for doc_id, score in score.items():\n",
    "            res.append((query_id, doc_id, score))\n",
    "            \n",
    "    # lets group in different list the results for each query\n",
    "    res_grouped = {}\n",
    "    for query_id, doc_id, score in res:\n",
    "        if query_id not in res_grouped:\n",
    "            res_grouped[query_id] = []\n",
    "        res_grouped[query_id].append((doc_id, score))\n",
    "\n",
    "    # lets sort the results for each query by score\n",
    "    for query_id in res_grouped:\n",
    "        res_grouped[query_id] = sorted(res_grouped[query_id], key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "    return res_grouped\n",
    "\n",
    "def get_run_id(folder_path=RUN_OUTPUT_FOLDER):\n",
    "    files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "    return len(files) + 1\n",
    "\n",
    "def display_top_k_results(results, k=10):\n",
    "    for query_id, doc_ids in results.items():\n",
    "        print(f\"Query {query_id}:\")\n",
    "        for i, (doc_id, score) in enumerate(doc_ids[:k]):\n",
    "            print(f\"\\t{i+1}. {doc_id} ({score})\")\n",
    "        print()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_name = \"BengezzouIdrissMezianeGhilas\"\n",
    "run_id = get_run_id()\n",
    "processing = textprocessor.get_text_processor_name()\n",
    "granularity = \"article\"\n",
    "run_file = f\"{RUN_OUTPUT_FOLDER}{team_name}_{run_id}_{model_wrapper.get_model_name()}_{granularity}_{processing}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formated_results = format_results(results)\n",
    "# display_top_k_results(formated_results)\n",
    "\n",
    "with open(run_file, \"w\") as f_out:\n",
    "    for query_id in formated_results:\n",
    "        for rank, (doc_id, score) in enumerate(formated_results[query_id]):\n",
    "            f_out.write(\"{} Q0 {} {} {} BengezzouIdrissMezianeGhilas /article[1]\\n\".format(query_id, doc_id, rank+1, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# write results to file\n",
    "with open(\"result.json\", \"w\") as f_out:\n",
    "    json.dump(results, f_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
