bottleneck method tz edward machin learn bottleneck method techniqu introduc tishbi al find best tradeoff accuraci complex compress summar cluster random variabl joint probabl distribut observ relev variabl applic includ distribut cluster dimens reduct well defin sens gener classic notion minim suffici statist parametr statist arbitrari distribut exponenti form relax suffici condit captur fraction mutual relev variabl compress variabl algorithm minimis quantiti underset ptxmin ixt beta iti ixtiti mutual inform xt ty gaussian bottleneck simpl applic bottleneck gaussian variat semblanc squar reduc rank canon correl assum jointli multivari normal vector covari sigma_xx sigma_yy compress version maintain mutual optimum normal vector consist linear combin element tax matrix orthogon row project matrix fact row select weight left eigenvector singular decomposit matrix gener asymmetr omega sigma_xi sigma_xx sigma_xi sigma_yy sigma_xyt sigma_xx defin singular decomposit omega ulambda vt lambda diag big lambda_ le lambda_ cdot lambda_n big critic valu beta_ underset lambda_i lt lambda_i number activ eigenvector project order approxim beta_mc lt beta le beta_mc final w_ u_ dot w_m u_m weight w_i sqrtbeta lambda_i lambda_i r_i r_i u_it sigma_xx u_i data cluster bottleneck applic bottleneck method nongaussian sampl data describ tishbi el concept treat complic independ phase exercis firstli estim unknown parent probabl densiti data sampl drawn secondli densiti theoret framework bottleneck densiti estim bottleneck method frame probabilist statist term estim underli probabl densiti sampl point x_i well problem number solut describ silverman method joint probabl sampl markov transit matrix method mathemat synergi bottleneck method defin arbitrarili increas distanc metric sampl pair distanc matrix d_ijf big big x_i x_j big big comput transit probabl sampl pair p_ijexp lambda d_ij lambda gt treat sampl normalis version markov transit probabl matrix vector probabl step condit initi ptpt interest equilibrium probabl vector pinfti usual domin eigenvector matrix independ initialis vector markov transit method establish probabl sampl point claim proport probabl densiti interpret eigenvalu distanc matrix discuss cluster soft cluster exampl refer vector sampl categori joint probabl pxi assum soft cluster c_k defin probabl distribut data sampl x_i c_k x_i tishbi al iter set equat determin cluster ultim gener blahutarimoto algorithm develop rate distort theori applic type algorithm neural network appear origin entropi argument aris applic gibb distribut determinist anneal begincas pcxkpc exp big betadkl big pyx py cbig big py ctextstyl sum_x pyxp px big pc pc textstyl sum_x pc px endcas function iter expand matrix valu set condit probabl a_ij pc_i x_j kpc_i exp big betadkl big pyx_j py c_ibig big kullback leibler distanc dkl vector gener sampl data gener reduc proxi appli assess fidel compress vector respect refer categor data fundament bottleneck equat dklab kullback leibler distanc distribut dkl ab sum_i pa_i log big fracpa_ipb_i big scalar normal weight neg expon distanc prior cluster probabl downweight kullback liebler distanc larg success cluster grow probabl unsuccess decay second matrixvalu set condit probabl b_ikpy_i x_k sum_k py_i x_k pc_j x_k px_kbig pc_j step deriv definit beginalign py_ic_k sum_j py_ix_jpx_jc_k sum_j py_ix_jpx_j c_k big pc_k sum_j py_ix_jpc_k x_j px_j big pc_k endalign bay ident pabpabpbpbapa find margin distribut cluster beginalign pc_i sum_j pc_i x_j sum_j pc_i x_j px_j endalign standard result input algorithm margin sampl distribut px determin domin eigenvector matrix valu kullback leibler distanc function d_ijkldkl big pyx_j py c_ibig big deriv sampl space transit probabl matrix py_i c_j initialis randomli reason guess matrix pc_i x_j prior valu algorithm converg multipl minima exist action resolv detail includ hard cluster method defin decis contour categor sampl extern train set appli previou distanc metric find transit probabl sampl tild px_i px_i kappa exp big lambda big big x_i big big big kappa normalis secondli appli line algorithm cluster condit categori probabl beginalign tild pc_i pc_i sum_j pc_i x_jpx_j sum_j pc_i x_j tild px_j py_i c_j sum_k py_i x_k pc_j x_kpx_k pc_j sum_k py_i x_k pc_j x_k tild px_k tild pc_j endalign final py_i sum_j py_i c_j pc_j sum_j py_i c_j tild pc_j paramet beta close supervis increas increas number featur categori probabl space snap focu critic threshold exampl case examin cluster quadrant multipli random input categori output pm gener ysignuv function properti spatial separ cluster categori demonstr method handl distribut sampl uniformli distribut squar number cluster number categori case perform cluster paramet lambda beta distanc function d_ij big x_i x_j big x_i u_iv_it condit distribut pyx matrix beginalign pry_i mboxif signu_iv_i pry_i mboxif signu_iv_i endalign summat incorpor valu repres train valu work well iter equat figur locat twenti sampl repres repres contour uniti likelihood ratio level pr big pr sampl scan squar theoret contour align coordin small sampl number spuriou cluster sampl point decis contour neural networkfuzzi logic analog analog algorithm neural network singl hidden layer intern node repres cluster c_j second layer network weight condit probabl pc_j x_i py_k c_j standard neural network algorithm reli entir probabl input sampl valu intern output valu condit probabl densiti distribut nonlinear function encapsul distanc metric influenc functionsradi basi function transit probabl sigmoid function blahutarimoto threelin algorithm converg rapidli ten iter vari beta lambda cardin cluster level focu data featur achiev statist soft cluster definit pc_i x_j overlap verbal fuzzi membership concept fuzzi logic bibliographi tishbi fc pereira bialek bottleneck method annual allerton confer commun control comput sep chechik globerson tishbi weiss bottleneck gaussian variabl journal machin learn jan tishbi slonim data cluster markovian relax bottleneck method neural process system nip bw silverman densiti estim statist data analysi chapman hall slonim tishbi document cluster word cluster bottleneck method sigir weiss segment eigenvector unifi view proceed ieee intern confer comput vision miller rao rose gersho informationtheoret learn algorithm neural network classif nip harremo tishbi bottleneck revisit choos good distort measur proceed intern symposium theori isit theori extern link paper tishbi al