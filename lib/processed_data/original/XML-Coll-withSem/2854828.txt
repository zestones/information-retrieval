multiarm bandit tz melcomb sequenti method machin learn multiarm bandit call karm bandit simpl machin learn problem base analog tradit slot machin onearm bandit lever pull lever reward drawn distribut associ specif lever object gambler maxim collect reward sum iter pull classic assum gambler initi knowledg lever crucial tradeoff gambler face trial exploit lever highest expect payoff explor expect payoff lever empir motiv multiarm bandit problem origin describ robbin simpl model agent simultan attempt acquir knowledg optim decis base exist knowledg practic exampl includ clinic trial effect experiment treatment investig minim patient loss adapt rout effort minim delay network question aris case problem balanc reward maxim base knowledg acquir attempt action increas knowledg exploit explor tradeoff reinforc learn model control dynam alloc resourc project answer question project work uncertainti difficulti payoff possibl multiarm bandit model multiarm bandit bandit short set real distribut r_ dot r_k distribut associ reward deliv lever mu_ dot mu_k valu associ reward distribut gambler iter play lever round observ associ reward object maxim sum collect reward horizon number round remain play bandit problem formal equival onest markov decis process regret rho round defin differ reward sum associ optim strategi sum collect reward rho mu sum_tt widehatr_t mu maxim reward mu max_k mu_k widehatr_t reward time strategi averag regret round rho probabl number play round infin zeroregret strategi intuit zeroregret strategi guarante converg optim strategi uniqu round play variat formul multiarm bandit arm repres independ markov machin time arm play machin advanc chosen markov evolut probabl reward depend current machin generalis call restless bandit problem nonplay arm evolv time whittl discuss system number choic arm play increas time arm acquir bandit common bandit strategi strategi exist provid approxim solut bandit problem three broad categori detail semiuniform strategi semiuniform strategi earliest simplest strategi discov solv bandit problem strategi common greedi behavior best lever base previou observ pull uniformli random action epsilongreedi strategi best lever select proport epsilon trial lever randomli select uniform probabl proport epsilon typic paramet epsilon vari depend circumst predilect epsilonfirst strategi pure explor phase pure exploit phase trial total explor phase occupi epsilon trial exploit phase epsilon trial explor phase lever randomli select uniform probabl exploit phase best lever select epsilondecreas strategi epsilongreedi strategi epsilon decreas experi progress highli explor behaviour start highli exploit behaviour finish probabl match strategi probabl match strategi reflect idea number pull lever match actual probabl optim lever price strategi price strategi establish price lever lever highest price pull refer robbin aspect sequenti design experi bulletin american mathemat societi volum richard sutton andrew barto reinforc learn mit press onlin bandit project banditsourceforgenet open sourc implement bandit strategi dayanik powel yamazaki polici discount bandit problem avail constraint httpwwwprincetonedusdayanikpapersbanditpdf peter whittl armacquir bandit ann probab onlin peter whittl restless bandit activ alloc chang appl prob sudipto guha kamesh munagala peng shi polici restless bandit problem arxivv warren powel approxim dynam program john wiley son york chapter gittin power gener strategi analyz bandit problem optim stop search theori