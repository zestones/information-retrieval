gener hebbian algorithm tz doi bot neural network gener hebbian algorithm gha literatur sanger rule linear feedforward neural network model unsupervis learn applic princip compon analysi defin oja rule formul stabil appli network multipl output theori gha combin oja rule gramschmidt process produc learn rule form delta w_ij etalefty_j x_i y_j sum_kj w_ik y_k w_ij defin synapt weight connect strength ith input jth output neuron input output vector eta learn rate paramet deriv matrix form oja rule written fracd wtd twt textrmdiag wt wtt wt gramschmidt algorithm delta wt textrmlow wt wtt wt wt matrix case repres synapt weight eta textbfx textbfxt autocorrel matrix simpli outer product input textrmdiag function diagon matrix textrmlow function set matrix element diagon equal combin equat origin rule matrix form delta wt etat lefttextbfyt textbfxtt textrmlttextbfyttextbfytt wtright function textrmlt set matrix element diagon equal note output textbfyt wt textbfxt linear neuron stabil pca applic gha applic selforgan map featur princip compon analysi exampl case includ artifici intellig speech imag process fact learn singlelay processthat synapt weight chang depend respons input output layer avoid multilay depend associ backpropag algorithm simpl predict tradeoff learn speed accuraci converg set learn rate paramet eta hebbian learn oja rule factor analysi princip compon analysi pca network refer sanger terenc optim unsupervis learn singlelay linear feedforward neural network neural network doi retriev haykin simon neural network comprehens foundat prentic hall isbn oja erkki novemb simplifi neuron model princip compon analyz journal mathemat biolog doi bf bf retriev