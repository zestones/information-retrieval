oja rule makkon neural network neurosci biophys oja learn rule simpli oja rule model neuron brain artifici neural network chang connect strength learn time modif standard hebb rule hebbian learn multipl normal solv stabil problem gener algorithm princip compon analysi thi comput form believ happen biolog neuron theori oja rule requir number simplif deriv final form demonstr stabl unlik hebb rule singleneuron special case gener hebbian algorithm howev oja rule gener vari degre stabil success formula oja rule defin chang presynapt weight textbf output respons neuron input textbf delta textbf textbf textbf eta textbf textbf eta learn rate chang time note bold symbol vector defin discret time iter rule continu iter frac dtextbf eta textbf textbf deriv simplest learn rule hebb rule conceptu term neuron fire togeth wire togeth compon form differ equat written w_i w_i eta textbf x_i textbf output thi time explicitli depend input vector textbf hebb rule ha synapt weight approach infin posit learn rate thi normal weight weight magnitud restrict correspond weight correspond onli input neuron ani weight mathemat thi form w_i frac w_i eta textbf x_i sum_ w_j eta textbf x_j note oja origin paper correspond sum quadratur familiar normal rule howev ani type normal linear will result loss gener step expand thi taylor seri small learn rate eta ll w_i frac w_i sum_j w_jp eta left frac x_i sum_j w_jp frac w_i sum_j x_j w_j sum_j w_jp right small eta higher order term bigo notat specif linear neuron output neuron equal sum product input synapt weight textbf sum_ x_j w_j specifi weight normal will necessari condit stabil textbf sum_ w_jp substitut expans oja rule w_i w_i eta x_i w_i stabil pca analyz converg singl neuron evolv oja rule extract princip compon featur data set furthermor extens gener hebbian algorithm creat multioja neural network extract mani featur desir allow princip compon analysi princip compon a_j extract dataset textbf associ vector textbf _j a_j textbf _j cdot textbf restor origin dataset textbf sum_j a_j textbf _j case singl neuron train oja rule find weight vector converg textbf princip compon time number iter approach infin defin set input vector x_i correl matrix r_ ij x_i x_j ha associ eigenvector textbf _j eigenvalu lambda_j varianc output oja neuron langl rangl converg time iter princip eigenvalu lim_ nrightarrowinfti result deriv lyapunov function analysi oja neuron necessarili converg strictli princip compon condit met origin learn rule importantli learn rate eta allow vari time onli sum diverg power sum converg sum_ infti eta infti sum_ infti eta lt infti gt output activ function textbf allow nonlinear nonstat continu differenti textbf textbf deriv bound time applic oja rule wa origin describ oja paper principl selforgan appli attribut alan ture pca ha long histori befor oja rule formal network comput model thu appli ani problem selforgan map ping featur extract primari interest therefor oja rule ha import place imag speech process expand easili higher dimens process thu abl integr multipl output quickli canon exampl binocular vision biolog oja subspac rule clear evid longterm potenti longterm depress biolog neural network normal input weight neuron output howev direct experiment evid oja rule activ biolog neural network biophys deriv gener rule possibl deriv requir retrograd signal postsynapt neuron biolog plausibl neural backpropag form delta w_ ij propto langl x_i y_j rangl epsilon leftlangl c_textrm pre sum_k w_ ik y_k cdot c_textrm post y_j rightrangl befor w_ ij synapt weight input output neuron input postsynapt output defin epsilon constant analog learn rate c_textrm pre c_textrm post presynapt postsynapt function model weaken signal time note angl bracket denot averag oper convolut pre postsynapt function frequenc space combin integr term convolut find thi arbitrarydimension gener oja rule oja subspac delta propto xcdot wcdot hebbian learn bcm theori synapt plastic gener hebbian algorithm gha selforgan map pca network princip compon analysi ica network independ compon analysi refer oja erkki novemb simplifi neuron model princip compon analyz journal mathemat biolog doi retriev haykin simon neural network comprehens foundat prentic hall isbn intrat nathan unsupervis learn neural comput lectur telaviv univers retriev oja erkki neural network princip compon subspac intern journal neural system ijn doi retriev friston kj cd frith rsj frackowiak octob princip compon analysi learn algorithm neurobiolog analysi proceed biolog scienc doi retriev link oja erkki oja learn rule scholarpedia