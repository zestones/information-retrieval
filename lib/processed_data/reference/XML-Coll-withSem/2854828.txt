multiarm bandit melcomb sequenti method machin learn multiarm bandit sometim call karm bandit simpl machin learn problem base analog tradit slot machin onearm bandit lever pull lever provid reward drawn distribut associ specif lever object gambler maxim collect reward sum iter pull classic assum gambler ha initi knowledg lever crucial tradeoff gambler face trial exploit lever ha highest expect payoff explor inform expect payoff lever empir motiv multiarm bandit problem origin describ robbin simpl model agent simultan attempt acquir knowledg optim decis base exist knowledg practic exampl includ clinic trial differ experiment treatment investig minim patient loss adapt rout effort minim delay network question aris case relat problem balanc reward maxim base knowledg alreadi acquir attempt action increas knowledg thi exploit vs explor tradeoff reinforc learn model control dynam alloc resourc differ project answer question project work uncertainti difficulti payoff possibl multiarm bandit model multiarm bandit bandit short set real distribut dot r_k distribut associ reward deliv lever dot mu_k valu associ reward distribut gambler iter play lever round observ associ reward object maxim sum collect reward horizon number round remain play bandit problem formal equival onest markov decis process regret rho round defin differ reward sum associ optim strategi sum collect reward rho mu sum_ widehat _t mu maxim reward mu max_k mu_k widehat _t reward time strategi averag regret round rho tend probabl number play round tend infin zeroregret strategi intuit zeroregret strategi guarante converg optim strategi necessarili uniqu round play variat anoth formul multiarm bandit ha arm repres independ markov machin time arm play machin advanc chosen accord markov evolut probabl reward depend current machin generalis call restless bandit problem nonplay arm evolv time whittl ha discuss system number choic arm play increas time arm acquir bandit common bandit strategi mani strategi exist provid approxim solut bandit problem three broad categori detail semiuniform strategi semiuniform strategi earliest simplest strategi discov approxim solv bandit problem strategi common greedi behavior best lever base previou observ alway pull uniformli random action epsilongreedi strategi best lever select proport epsilon trial anoth lever randomli select uniform probabl proport epsilon typic paramet valu epsilon thi vari wide depend circumst predilect epsilonfirst strategi pure explor phase follow pure exploit phase trial total explor phase occupi epsilon trial exploit phase epsilon trial dure explor phase lever randomli select uniform probabl dure exploit phase best lever alway select epsilondecreas strategi epsilongreedi strategi valu epsilon decreas experi progress result highli explor behaviour start highli exploit behaviour finish probabl match strategi probabl match strategi reflect idea number pull lever match actual probabl optim lever price strategi price strategi establish price lever lever highest price alway pull refer robbin aspect sequenti design experi bulletin american mathemat societi volum richard sutton andrew barto reinforc learn mit press avail onlin bandit project banditsourceforgenet open sourc implement mani bandit strategi dayanik powel yamazaki polici discount bandit problem avail constraint http wwwprincetonedusdayanikpapersbanditpdf peter whittl armacquir bandit ann probab avail onlin peter whittl restless bandit activ alloc chang appl prob sudipto guha kamesh munagala peng shi polici restless bandit problem warren powel approxim dynam program john wiley son york chapter gittin power gener strategi analyz bandit problem optim search theori