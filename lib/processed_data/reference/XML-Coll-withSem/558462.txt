inform bottleneck method edward machin learn inform bottleneck method techniqu introduc tishbi al find best tradeoff accuraci complex compress summar eg cluster random variabl joint probabl distribut observ relev variabl applic includ distribut cluster dimens reduct well defin sens gener classic notion minim suffici statist parametr statist arbitrari distribut necessarili exponenti form doe relax suffici condit captur fraction mutual inform relev variabl compress variabl algorithm minimis follow quantiti underset tx min beta mutual inform respect gaussian inform bottleneck rel simpl applic inform bottleneck gaussian variat thi ha semblanc squar reduc rank canon correl assum jointli multivari normal vector covari sigma_ xx sigma_ yy compress version maintain valu mutual inform optimum normal vector consist linear combin element tax matrix ha orthogon row project matrix fact row select weight left eigenvector singular valu decomposit follow matrix gener asymmetr omega sigma_ xi sigma_ xx sigma_ xy sigma_ yy sigma_ xy sigma_ xx defin singular valu decomposit omega ulambda vt lambda diag big le cdot lambda_n big critic valu beta_ic underset lambda_i lt lambda_i number activ eigenvector project order approxim beta_ lt beta le beta_mc final dot w_m u_m weight w_i sqrt beta lambda_i lambda_i r_i r_i u_it sigma_ xx u_i data cluster inform bottleneck thi applic bottleneck method nongaussian sampl data describ tishbi el concept treat complic independ phase exercis firstli estim unknown parent probabl densiti data sampl drawn secondli densiti inform theoret framework bottleneck densiti estim sinc bottleneck method frame probabilist statist term estim underli probabl densiti sampl point x_i thi well problem number solut describ silverman method joint probabl sampl markov transit matrix method thi ha mathemat synergi bottleneck method defin arbitrarili increas distanc metric sampl pair distanc matrix d_ big big x_i x_j big big comput transit probabl sampl pair p_ exp lambda d_ lambda gt treat sampl normalis version markov transit probabl matrix vector probabl step condit initi pt interest onli equilibrium probabl vector infti usual domin eigenvector matrix independ initialis vector thi markov transit method establish probabl sampl point claim proport probabl densiti interpret eigenvalu distanc matrix discuss cluster follow soft cluster exampl refer vector sampl categori joint probabl assum soft cluster c_k defin probabl distribut data sampl x_i c_k x_i tishbi al follow iter set equat determin cluster ultim gener blahutarimoto algorithm develop rate distort theori applic thi type algorithm neural network appear origin entropi argument aris applic gibb distribut determinist anneal begin case cx kp exp big beta kl big yx big big textstyl sum_x yx big textstyl sum_x end case function iter expand follow thi matrix valu set condit probabl a_ c_i x_j kp c_i exp big beta kl big yx_j c_i big big kullback leibler distanc kl vector gener sampl data gener reduc inform proxi appli assess fidel compress vector respect refer categor data accord fundament bottleneck equat kl ab kullback leibler distanc distribut kl ab sum_i a_i log big frac a_i b_i big scalar normal weight neg expon distanc prior cluster probabl downweight kullback liebler distanc larg thu success cluster grow probabl unsuccess decay thi second matrixvalu set condit probabl b_ y_i x_k sum_k y_i x_k c_j x_k x_k big c_j step deriv thi follow definit begin align y_ic_k sum_j y_ix_j x_jc_k sum_j y_ix_j x_j c_k big c_k sum_j y_ix_j c_k x_j x_j big c_k end align bay ident ab ba thi find margin distribut cluster begin align c_i sum_j c_i x_j sum_j c_i x_j x_j end align thi standard result input algorithm margin sampl distribut ha alreadi determin domin eigenvector matrix valu kullback leibler distanc function d_ kl kl big yx_j c_i big big deriv sampl space transit probabl matrix y_i c_j initialis randomli reason guess matrix c_i x_j prior valu algorithm converg multipl minima exist action resolv detail includ hard cluster method defin decis contour categor sampl extern train set appli previou distanc metric find transit probabl sampl tild x_i x_i kappa exp big lambda big big x_i big big big kappa normalis secondli appli algorithm cluster condit categori probabl begin align tild c_i c_i sum_j c_i x_j x_j sum_j c_i x_j tild x_j y_i c_j sum_k y_i x_k c_j x_k x_k c_j sum_k y_i x_k c_j x_k tild x_k tild c_j end align final y_i sum_j y_i c_j c_j sum_j y_i c_j tild c_j paramet beta close supervis sinc increas increas number featur categori probabl space snap focu critic threshold exampl follow case examin cluster quadrant multipli random input categori output pm gener ysign uv thi function ha properti spatial separ cluster categori demonstr method handl distribut sampl uniformli distribut squar number cluster number categori thi case ha littl perform result cluster paramet lambda beta distanc function d_ big x_i x_j big x_i u_i v_i condit distribut yx matrix begin align pr mbox sign u_iv_i pr mbox sign u_iv_i end align elsewher summat onli incorpor valu repres train valu work quit well iter equat figur locat twenti sampl repres repres contour uniti likelihood ratio level pr big pr sampl scan squar theoret contour align coordin small sampl number follow spuriou cluster sampl point decis contour neural networkfuzzi logic analog analog thi algorithm neural network singl hidden layer intern node repres cluster c_j second layer network weight condit probabl c_j x_i y_k c_j respect howev unlik standard neural network algorithm reli entir probabl input sampl valu themselv intern output valu condit probabl densiti distribut nonlinear function encapsul distanc metric influenc functionsradi basi function transit probabl sigmoid function blahutarimoto threelin algorithm converg rapidli ten iter vari beta lambda cardin cluster variou level focu data featur achiev statist soft cluster definit c_i x_j ha overlap verbal fuzzi membership concept fuzzi logic bibliographi tishbi fc pereira bialek inform bottleneck method annual allerton confer commun control comput sep chechik globerson tishbi weiss inform bottleneck gaussian variabl journal machin learn jan tishbi slonim data cluster markovian relax inform bottleneck method neural inform process system nip bw silverman densiti estim statist data analysi chapman hall slonim tishbi document cluster word cluster inform bottleneck method sigir weiss segment eigenvector unifi view proceed ieee intern confer comput vision miller rao rose gersho informationtheoret learn algorithm neural network classif nip harremo tishbi inform bottleneck revisit choos good distort measur proceed intern symposium inform theori isit inform theori extern link paper tishbi al