gradient descent doubleblu optim algorithm analyt method call steepest descent method steepest descent gradient descent optim algorithm find local minimum function gradient descent step proport neg gradient approxim gradient function current point step proport gradient approach local maximum function procedur gradient ascent gradient descent steepest descent method steepest descent gradient descent confus method steepest descent approxim integr descript gradient descent base observ realvalu function mathbf defin differenti neighborhood point mathbf mathbf decreas fastest goe mathbf direct neg gradient mathbf nabla mathbf follow mathbf mathbf gammanabla mathbf gamma gt small number mathbf geq mathbf thi observ mind start guess mathbf local minimum consid sequenc mathbf mathbf mathbf dot mathbf mathbf _ngamma_n nabla mathbf _n ge mathbf ge mathbf ge mathbf ge dot hope sequenc mathbf _n converg desir local minimum note valu step size gamma allow chang everi iter thi process illustr pictur assum defin plane graph ha bowl shape blue curv contour region valu constant red arrow origin point direct neg gradient point note neg gradient point orthogon contour point gradient descent lead bottom bowl point valu function minim exampl gradient descent ha problem patholog function rosenbrock function rosenbrock function ha narrow curv valley minimum bottom valley veri flat becaus curv flat valley optimis zigzag slowli small stepsiz minimum gradient ascent method appli sinleft frac frac right co gradient descent algorithm action contour gradient descent algorithm action surfac comment gradient descent work space ani number dimens infinitedimension case search space typic function space calcul gteaux deriv function minim determin descent direct weak gradient descent algorithm mani iter converg local minimum curvatur differ direct veri differ find optim gamma step timeconsum convers gamma yield poor result method base newton method invers hessian conjug gradient techniqu better altern power algorithm bfg method consist calcul everi step matrix gradient vector multipli better direct combin sophist search algorithm find best valu gamma gradient descent fact euler method solv ordinari differenti equat appli gradient flow goal find minimum flow error finit method signific comput exampl gradient descent algorithm appli find local minimum function deriv implement program languag includ includ includ int main calcul expect local minimum occur algorithm start doubl xold doubl xnew doubl ep step size doubl precis fab xnew xold gt precis xold xnew xnew xnew ep xnew xnew xnew xnew printf local minimum occur lgn xnew thi precis algorithm converg local minimum iter robust implement algorithm check function valu inde decreas everi iter step size smaller otherwis adapt step size algorithm converg faster conjug gradient stochast gradient descent newton method optim search delta rule wolf condit refer mordecai avriel nonlinear program analysi method dover publish isbn jan snyman practic mathemat optim introduct basic optim theori classic gradientbas algorithm springer publish isbn