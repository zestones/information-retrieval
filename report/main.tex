\documentclass[a4paper, 12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{lmodern}
\usepackage{moreverb}
\usepackage{multicol}
\usepackage{hyperref}
\usepackage{url}

\usepackage{geometry}
\usepackage{booktabs}

\geometry{a4paper, total={6in, 9in}}
\def\UrlBreaks{\do\/\do-}  % Permet des sauts de ligne dans les URL au niveau des "/" et des "-"

\usepackage{float}
\usepackage[a4paper,left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}

\pagestyle{headings}
\pagestyle{plain}

\usepackage{listings} 


\setcounter{secnumdepth}{4}
\setcounter{tocdepth}{4}
\makeatletter


\makeatother

\makeatletter
\def\toclevel@subsubsubsection{4}
\def\toclevel@paragraph{5}
\def\toclevel@subparagraph{6}
\makeatother

\setlength{\parindent}{0cm}
\setlength{\parskip}{1ex plus 0.5ex minus 0.2ex}
\newcommand{\hsp}{\hspace{20pt}}
\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}


\begin{document}

\begin{titlepage}
  \begin{sffamily}
  \begin{center}

   
    \textsc{\LARGE }\\[2cm]

    \textsc{\Large M2 DSC - Université Jean Monnet}\\[1.5cm]

    % Title
    \HRule \\[0.4cm]
    { \huge  \textsc{Information Retrieval} \\
    \textsc{\Large Rapport de projet} \\[0.4cm] }
	
    \HRule \\[2cm]
    \textsc {Idriss BENGUEZZOU \\Ghilas MEZIANE}
 \begin{figure}
     \centering
    \includegraphics[scale=0.2]{logoUJM.png}
     \label{fig:ujm_logo}
 \end{figure}

    \vfill

    % Bottom of the page
    {\large {} 02/02/2024}

  \end{center}
  \end{sffamily}
\end{titlepage}

\newpage

\tableofcontents

\newpage

\section{Introduction}
Ce projet a pour but de mettre en pratique les notions vues en cours et en TD. 
Il s'agit de réaliser un système de recherche d'information sur un corpus de documents, en utilisant les méthodes vues en cours. 
Le corpus de documents est constitué de 9804 documents, et les requêtes sont au nombre de sept.

L'idée est de répondre aux exigences spécifiques de compétitions comme l'INEX, qui imposent des standards stricts pour évaluer les performances des systèmes de recherche d'information.
Notre rapport détaillera notre démarche, les choix méthodologiques, les paramétrages utilisés, et les résultats obtenus, en mettant particulièrement 
l'accent sur notre démarche de recherche de la meilleure configuration possible pour notre système de recherche d'information.


\section{Méthodologie}

Nous avons choisi de travailler avec le langage de programmation Python, au vu de sa popularité et de sa richesse en bibliothèques pour le traitement de texte. 
En outre, aucune bibliothèque n'a été utilisée pour la recherche d'information, l'indexation, ou le calcul de similarité. Nous allons détailler notre démarche pour chaque étape du projet.

\subsection{Prétraitement des données}

Lors de nos expérimentations, nous avons constaté que l'étape de prétraitement des données est cruciale pour la qualité des résultats obtenus.
En effet, tout au long de nos expérimentations, nous avons constaté que les résultats obtenus étaient très sensibles à la qualité du prétraitement des données. 
Avec un prétraitement de qualité, nous avons pu améliorer notre score de MaGP de 0.198 à 0,2512. 

Tout d'abord, nous avons utilisé la bibliothèque \texttt{nltk} pour le prétraitement des données.
Nous avons utilisé la fonction \texttt{word\_tokenize} pour la tokenisation des documents, et la fonction \texttt{PorterStemmer} pour la racinisation des mots.
Nous avons également utilisé la liste de stopwords fournie en cours pour élimer les mots vides.

\subsubsection{Prétraitement des données initial}

Notre implémentation initiale des étapes de prétraitement des données a été la suivante:

\begin{enumerate}
  \item Tokenisation
  \item Mise en minuscule
  \item Racinisation des mots (stemming)
  \item Élimination des mots vides (suppression des stopwords)
  \item Élimination de la ponctuation
  \item Élimination des nombres
  \item Élimination des caractères spéciaux
  \item Élimination des mots chaines de caractères vides  
\end{enumerate}

Ces étapes de prétraitement des données était réaliser à chaque fois que nous devions indexer les documents.
Nous verrons plus tard que par soucis d'optimisation des temps, nous avons choisi de réaliser ces étapes de prétraitement des données une seule fois, et de sauvegarder les résultats dans une nouvelle collection.
Nous avons nommé cette première méthode de prétraitement des données : \texttt{Processing Reference},
car elle est réalisée à chaque fois que nous devons indexer les documents.
Voici les statistiques de notre collection après cette première méthode de prétraitement des données:

\begin{table}[!h]
  \begin{minipage}{0.35\linewidth}
      \centering
      \resizebox{\textwidth}{!}{%
          \begin{tabular}{|c|c|c|}
              \hline
              \textbf{Statistiques} & \textbf{Valeur} \\
              \hline
              Taille moyenne des documents &  654.008 \\
              Taille moyenne des mots &  8.391 \\
              Nombre de mots unique &  210,232 \\
              Nombre de mots total &  6.41189e+06 \\
              \hline
          \end{tabular}%
      }
      \caption{Statistiques de la collection}
  \end{minipage}%
  \hspace{0.05\linewidth} % Add a 5% width margin
  \begin{minipage}{0.60\linewidth}
      Ces valeurs sont obtenues après avoir réalisé les étapes de prétraitement des données décrites ci-dessus.
      Elles nous ont permis d'avoir une référérence pour la suite de nos expérimentations, et de comparer les résultats obtenus avec d'autres méthodes de prétraitement des données.
      Une run de notre système de recherche d'information avec ces valeurs nous a donné un score de MaGP de 0.198.
  \end{minipage}
\end{table}

\subsubsection{Optimisation du Prétraitement des Données : Expérimentations avec un Ordre Modifié des Étapes}

Suite à quelque expérimentations, nous avons constaté plusieurs choses qui nous ont poussé à modifier l'ordre des étapes de prétraitement des données.
Nous avons remarqué que l'étape de \texttt{tokenisation} ne fonctionnait pas correctement par moment, par exemple:
En tokenisant la phrase "World Ltd. World Ltd." nous obtenions ["World", "Ltd", ".", "World", "Ltd."] au lieu de ["world", "ltd", ".", "world", "ltd", "."]. 
En effet, en menant quelques recherches, nous avons remarqué que la tokenisation pouvais ne pas fonctionner correctement avec les abréviations, les mots vides, et les mots composés.
Nous avons donc décidé de modifier l'ordre des étapes de prétraitement des données, et de réaliser la tokenisation après l'élimination de la ponctuation, des nombres, et des caractères spéciaux.

De plus, en parcourant notre liste de mots vides (stopwords), nous avons remarqué que tout les mots présent dans 
cette liste était en minuscule. Donc il était nécessaire de mettre en minuscule les mots avant de chercher à
éliminer les mots vides. C'est à ce moment que nous avons remarqué que l'étape de racinisation des mots (stemming)
était réalisée avant l'étape de suppression des mots vides. Ce qui fait que les mots vides n'étaient pas éliminés
correctement. Nous avons donc décidé de réaliser la racinisation des mots après l'élimination des mots vides.

Notre nouvelle méthode de prétraitement des données est la suivante:
\begin{enumerate}
  \item Élimination de la ponctuation
  \item Élimination des nombres
  \item Élimination des caractères spéciaux
  \item Tokenisation
  \item Mise en minuscule
  \item Élimination des mots vides (suppression des stopwords)
  \item Racinisation des mots (stemming)
  \item Élimination des mots chaines de caractères vides  
\end{enumerate}

Nous avons nommé cette nouvelle méthode de prétraitement des données : \texttt{Processing Reference Réarrangé}.
Voici les statistiques de notre collection après cette nouvelle méthode de prétraitement des données:

\begin{table}[!h]
  \begin{minipage}{0.35\linewidth}
      \centering
      \resizebox{\textwidth}{!}{%
          \begin{tabular}{|c|c|c|}
              \hline
              \textbf{Statistiques} & \textbf{Valeur} \\
              \hline
              Taille moyenne des documents &  628.267 \\
              Taille moyenne des mots &  9.227 \\
              Nombre de mots unique &  226,564 \\
              Nombre de mots total &  6.15953e+06 \\
              \hline
          \end{tabular}%
      }
      \caption{Statistiques de la collection}
  \end{minipage}%
  \hspace{0.05\linewidth} % Add a 5% width margin
  \begin{minipage}{0.60\linewidth}
    Nous pouvons tout de suite remarquer que la taille moyenne des documents a légèrement diminué, 
    et que la taille moyenne des mots a légèrement augmenté. Le vocabulaire de notre collection a également
    augmenté. De plus nous avons un total de mots légèrement inférieur à la première méthode de prétraitement des données, 
    environ 25,000 mots de moins.    
  \end{minipage}
\end{table}

Pour évaluer l'amplitude de l'impact de cette nouvelle méthode de prétraitement des données, 
nous avons décidé d'observer la fréquence des mots de nos requêtes avant et après cette nouvelle méthode.

\begin{table}[!h]
    \centering
    \resizebox{\textwidth}{!}{%
        \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|}
            \hline
            \textbf{} & \textbf{actor} & \textbf{algorithm} & \textbf{analysi} &
            \textbf{benefit} & \textbf{exclus} & \textbf{film} & \textbf{health} &
            \textbf{hill} & \textbf{inform} & \textbf{learn} & \textbf{link} & 
            \textbf{machin} \\
            \hline
            \textbf{Processing Reference} & 7086 & 35062 & 8085 & 4671 & 1888 & 16595 & 11391 & 4513 & 17440 & 6003 & 12090 & 9122 \\
            \textbf{Processing Reference Réarrangé} & 7113 & 35326 & 8164 & 4716 & 1891 & 16708 & 11411 & 4526 & 0 & 6028 & 12306 & 9160 \\
            \textbf{Différence} & 27 & 264 & 79 & 45 & 3 & 113 & 20 & 13 & -17440 & 25 & 216 & 38 \\
            \hline
        \end{tabular}%
    }
    \caption{Fréquence des mots des requêtes (Partie 1)}
\end{table}

\begin{table}[!h]
    \centering
    \resizebox{\textwidth}{!}{%
        \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
            \hline
            \textbf{} & \textbf{model} & \textbf{mutual} & \textbf{network} &
            \textbf{oil} & \textbf{oliv} & \textbf{oper} & \textbf{probabilist} & 
            \textbf{rank} & \textbf{retriev} & \textbf{score} & \textbf{supervis} &
            \textbf{system} & \textbf{web} \\
            \hline
            \textbf{Processing Reference} & 15337 & 2708 & 17820 & 14270 & 3023 & 16591 & 1230 & 3643 & 13560 & 4179 & 588 & 38683 & 20128 \\
            \textbf{Processing Reference Réarrangé} & 15422 & 2711 & 17968 & 14409 & 3027 & 16622 & 1229 & 3680 & 13570 & 4198 & 589 & 39351 & 20188 \\
            \textbf{Différence} & 85 & 3 & 148 & 139 & 4 & 31 & -1 & 37 & 10 & 19 & 1 & 668 & 60 \\
            \hline
        \end{tabular}%
    }
    \caption{Fréquence des mots des requêtes (Partie 2)}
\end{table}
Nous avons au total -15393 mots sur les mots de la requête. Nous remarquons immédiatement que le mot "information" (inform) à disparu de notre collection.
Cela est dû à l'étape de suppression des mots vides (stopwords), qui a éliminé le mot "information" de notre collection.
Ceci confirme que nos étapes de prétraitement sont bien réalisées 

Après avoir retiré le mot "information" de notre list de mots vides (stopwords), 
nous avons un total de 2119 mots en plus sur les mots de la requête.

Voici une nouvelle fois les statistiques de notre collection après cette nouvelle méthode de prétraitement :

\begin{table}[!h]
  \begin{minipage}{0.35\linewidth}
      \centering
      \resizebox{\textwidth}{!}{%
          \begin{tabular}{|c|c|c|}
              \hline
              \textbf{Statistiques} & \textbf{Valeur} \\
              \hline
              Taille moyenne des documents &  650.929  \\
              Taille moyenne des mots & 8.42026 \\
              Nombre de mots unique &  211,770 \\
              Nombre de mots total &  6.3817e+06 \\
              \hline
          \end{tabular}%
      }
      \caption{Statistiques de la collection}
  \end{minipage}%
  \hspace{0.05\linewidth} % Add a 5% width margin
  \begin{minipage}{0.60\linewidth}
    Nous récupérons maintenant environs 150,000 mots en plus avec une taille moyenne des mots légèrement inférieure.    
    En théorie, nous devrions obtenir de meilleurs résultats avec cette nouvelle méthode, donc en ce basant sur cette
    hypothèse, nous avons décider d'améliorer encore un peu plus notre méthode de prétraitement des données.
  \end{minipage}

\end{table}

\subsubsection{Optimisation du Prétraitement des Données : Expérimentations avec l'Élimination des Mots Rares}
Nous avions remarqué que le vocabulaire de notre collection était très grand, 
nous avions environs 200,000 mots uniques. Cependant, en observant les mots de notre vocabulaire, 
nous nous sommes rendu compte que beaucoup de mots avait une fréquence très faible ou ne possédaient 
aucun sens. Nous avons donc décidé de créer une liste de mots que nous avons nommé \texttt{outliers},
qui contient les mots qui apparaissent moins de 5 fois dans notre collection et les mots ayant 
une longueur inférieure à 3 caractères. Nous avons ensuite éliminé ces mots de notre collection.


Voici les statistiques de notre collection après cette nouvelle méthode de prétraitement des données:

\begin{table}[!h]
  \begin{minipage}{0.35\linewidth}
      \centering
      \resizebox{\textwidth}{!}{%
          \begin{tabular}{|c|c|c|}
              \hline
              \textbf{Statistiques} & \textbf{Valeur} \\
              \hline
              Taille moyenne des documents &  580.832  \\
              Taille moyenne des mots & 6.68121 \\
              Nombre de mots unique &  40,763 \\
              Nombre de mots total &  5.69448e+06 \\
              \hline
          \end{tabular}%
      }
      \caption{Statistiques de la collection}
  \end{minipage}%
  \hspace{0.05\linewidth} % Add a 5% width margin
  \begin{minipage}{0.60\linewidth}
    A l'aide de cette nouvelle méthode notre vocabulaire est maintenant constitué de 40,763 mots uniques,
    avec une taille moyenne des mots de 6.68121. Nous avons donc réduit notre vocabulaire de plus de 150,000 mots.
    Nous avons également une taille moyenne des documents de 580.832 mots, ce qui est une réduction de 70 mots par rapport à la méthode précédente.
  \end{minipage}
\end{table}

\section{Méthodes et Paramétrages}

Nous avons utilisé plusieurs méthodes et modèles pour la recherche d'information et avons 
réalisé plusieurs expérimentations pour essayé de trouver la meilleure configuration possible. Nous présentons
dans cette section les différentes méthodes et modèles que nous avons utilisé, ainsi que les paramétrages que nous avons utilisé, 
et les résultats obtenus.

\subsection{Méthodes de Recherche d'Information}

\subsubsection{Méthodes de Recherche d'Information : Smart LTN}

Le poids TF-IDF (\textit{Term Frequency-Inverse Document Frequency}) d'un terme dans un document est déterminé par la formule suivante :

\begin{equation}
\text{TF-IDF}(i, d) = \left(1 + \log_{10}(\text{TF}(i, d))\right) \times \text{IDF}(i)
\end{equation}

où :
\begin{itemize}
    \item $\text{TF}(i, d)$ représente la fréquence du terme $i$ dans le document $d$.
    \item $\text{IDF}(i)$ est la fréquence inverse du document pour le terme $i$.
\end{itemize}

Les composants individuels sont calculés de la manière suivante :

\begin{equation}
\text{IDF}(i) = \log_{10}\left(\frac{\text{Taille de la Collection}}{\text{Fréquence du Terme}(i)}\right)
\end{equation}

\begin{equation}
\text{TF}(i, d) = \text{Fréquence du Terme}(i, d)
\end{equation}

Dans le cadre de notre système, l'$\text{IDF}$ et le $\text{TF}$ sont calculés en tenant compte des balises ciblées.

\begin{table}[h]
    \centering
    \begin{tabular}{l c c}
        \toprule
        \textbf{Run Name} & \textbf{MAGP Value} & \textbf{P[0, 1]} \\
        \midrule
        \dots\_5\_ltn\_article\_stop670\_porter & 0.1687 & 0.3835 \\
        \dots\_8\_ltn\_article\_stop670\_nostem & 0.1699 & 0.3996 \\
        \dots\_11\_ltn\_article\_nostop\_porter & 0.1515 & 0.3265 \\
        \dots\_14\_ltn\_article\_nostop\_nostem & 0.1699 & 0.3996 \\
        \bottomrule
    \end{tabular}
    \caption{Résultats de la méthode Smart LTN}
    \label{tab:result_ltn}
\end{table}

Nous pouvons remarquer que le fait de ne pas éliminer les mots vides (stopwords) 
a un impact négatif sur les résultats obtenus. En effet, les runs 8 et 14 ont obtenu les meilleurs résultats,
avec un score de MaGP de 0.1699, et un P[0, 1] de 0.3996. Nous avons également remarqué que la racinisation des mots (stemming)
n'a pas d'impact significatif sur les résultats obtenus. En effet, les runs 8 et 14 ont obtenu les mêmes résultats,
alors que le run 8 a été réalisé avec la racinisation des mots, et le run 14 sans la racinisation des mots.



\newpage

\subsubsection{Méthodes de Recherche d'Information : Smart LTC}
Le schéma de pondération LTC (Logarithmique-Term Frequency and Cosine Normalization) optimise la précision des recherches en ajustant les poids des termes selon leur fréquence et la longueur des documents. Voici les étapes clés de notre implémentation :

\begin{enumerate}
\item \textbf{Calcul du Poids LTC} : Utilise la fréquence logarithmique du terme (L), la fréquence inverse du document (T), et la normalisation cosinus (C) pour équilibrer l'importance des termes entre documents de longueurs variées.

\item \textbf{Fréquence Logarithmique du Terme (L)} :
\begin{equation}
L(i, d) = 1 + \log_{10}(\text{TF}(i, d))
\end{equation}
$\text{TF}(i, d)$ représente la fréquence du terme $i$ dans le document $d$.

\item \textbf{Fréquence Inverse du Document (T)} :
\begin{equation}
T(i) = \log_{10}\left(\frac{N}{\text{DF}(i)}\right)
\end{equation}
$N$ est le nombre total de documents, et $\text{DF}(i)$ le nombre de documents contenant le terme $i$.

\item \textbf{Normalisation Cosinus (C)} :
\begin{equation}
C(d) = \frac{1}{\sqrt{\sum_{i \in d} (L(i, d) \times T(i))^2}}
\end{equation}
\item \textbf{Poids Final LTC} :
\begin{equation}
\text{LTC}(i, d) = (L(i, d) \times T(i)) \times C(d)
\end{equation}
\end{enumerate}

L'implémentation de ce schéma a permis à notre système une évaluation équilibrée des termes en fonction de leur fréquence et de la longueur des documents, améliorant la pertinence des résultats de recherche.
\begin{table}[h]
    \centering
    \begin{tabular}{l c c}
        \toprule
        \textbf{Run Name} & \textbf{MAGP Value} & \textbf{P[0, 1]} \\
        \midrule
        BengezzouIdrissMezianeGhilas\_6\_ltc\_article\_stop670\_porter & 0.0834 & 0.22818 \\
        BengezzouIdrissMezianeGhilas\_9\_ltc\_article\_stop670\_nostem & 0.0699& 0.1987 \\
        BengezzouIdrissMezianeGhilas\_12\_ltc\_article\_nostop\_porter & 0.0668 & 0.1930 \\
        BengezzouIdrissMezianeGhilas\_15\_ltc\_article\_nostop\_nostem & 0.0699 & 0.1987 \\
        \bottomrule
    \end{tabular}
    \caption{Résultats de la méthode Smart LTC}
    \label{tab:result_ltn}
\end{table}

\subsubsection{Méthodes de Recherche d'Information : Smart LNU}
Le schéma de pondération LNU (Logarithmic Normalization and Unique-term adjustment) optimise la recherche d'informations en ajustant les poids des termes selon leur fréquence, la longueur des documents, et le nombre de termes distincts. Voici le processus détaillé :

\begin{enumerate}
\item \textbf{Calcul de la Fréquence Logarithmique Normalisée (LNN)} : Diminue l'effet des termes fréquemment répétés en les soumettant à une transformation logarithmique, renforçant l'importance des termes moins communs.
\begin{equation}
\text{LNN}(i, d, x) = 1 + \log_{10}(\text{TF}(i, d, x))
\end{equation}
$\text{TF}(i, d, x)$ indique la fréquence du terme $i$ dans le document $d$ et le chemin XPath $x$.

\item \textbf{Normalisation par la Longueur des Documents} : Compense les variations de longueur entre les documents, permettant une comparaison équitable des poids des termes.
\begin{equation}
\text{LN}(d, t) = 1 + \log_{10}\left(\frac{\text{Length}(d, t)}{\text{AVDL}(t)}\right)
\end{equation}
où $\text{Length}(d, t)$ est la longueur du document $d$ pour le tag $t$, et $\text{AVDL}(t)$ est la longueur moyenne des documents pour le tag $t$.

\item \textbf{Ajustement Basé sur le Nombre de Termes Distincts} : Prend en compte la diversité lexicale du document pour ajuster le poids des termes, favorisant une évaluation plus nuancée.
\begin{equation}
\text{Adjustement}(d) = (1 - \text{slope}) + \text{slope} \times \frac{\text{NTD}(d)}{\text{Pivot}}
\end{equation}
$\text{NTD}(d)$ est le nombre de termes distincts dans le document $d$, et $\text{Pivot}$ est le nombre moyen de termes distincts dans tous les documents. Le paramètre $\text{slope}$ ajuste l'influence de la diversité des termes.

\item \textbf{Calcul du Poids Final} : Intègre la fréquence des termes, la longueur des documents, et la diversité des termes pour déterminer le poids final d'un terme dans un document.
\begin{equation}
\text{Weight}(i, d, x) = \frac{\text{LNN}(i, d, x)}{\text{LN}(d, t)} / \text{Adjustement}(d)
\end{equation}
\end{enumerate}

Le schéma LNU représente une approche sophistiquée pour évaluer la pertinence des termes en prenant en compte leur distribution dans les documents, la structure des documents, et la variété lexicale. Cette méthode permet d'affiner la pertinence des résultats de recherche en assurant une analyse détaillée et contextualisée des termes.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{LNU_magp_results.png}
    \caption{MaGP pour LNU en fonction de différents slopes}
    \label{fig:lnu_results}
\end{figure}

\newpage


\newpage

\subsubsection{Méthodes de Recherche d'Information : BM25}

La méthode de pondération BM25, également connue sous le nom de Best Matching 25,
est une technique couramment utilisée en recherche d'information pour attribuer des poids aux termes dans un index inversé.
Cette méthode prend en compte la fréquence du terme dans un document, la fréquence du terme dans l'ensemble de la collection,
et la longueur du document.

Le calcul du poids BM25 pour un terme dans un document est défini par la formule suivante :

\begin{equation}
\text{BM25}(i, d) = \frac{{\text{TF} \times (\text{k1} + 1)}}{{\text{k1} \times \left((1 - \text{b}) + \text{b} \times \left(\frac{\text{DL}}{\text{AVDL}}\right)\right) + \text{TF}}} \times \text{IDF}
\end{equation}

où :
\begin{itemize}
    \item $\text{TF}$ est la fréquence du terme dans le document.
    \item $\text{DL}$ est la longueur du document.
    \item $\text{AVDL}$ est la longueur moyenne des documents dans la collection.
    \item $\text{IDF}$ est la fréquence inverse du document pour le terme.
    \item $\text{k1}$ et $\text{b}$ sont des paramètres de réglage qui contrôlent l'impact de la fréquence du terme et de la longueur du document, respectivement. \\
\end{itemize}

La mise en œuvre de la méthode BM25 dans notre système de recherche d'information est réalisée par la  classe \texttt{BM25Weighting}, héritant de la classe abstraite \texttt{WeightingStrategy}. Cette classe propose une méthode \texttt{calculate\_weight} 
qui construit l'index inversé pondéré en utilisant la pondération BM25. 
Les paramètres $\text{k1}$ et $\text{b}$ sont configurables lors de l'instanciation de la classe \texttt{BM25Weighting}, pour permettre d'expérimenter avec différentes valeurs de ces paramètres.

Les résultats obtenus avec cette méthode seront présentés dans la section suivante,
soulignant son impact sur les performances du système de recherche d'information.


\begin{table}[h]
  \centering
  \begin{tabular}{l c c}
      \toprule
      \textbf{Run Name} & \textbf{MAGP Value} & \textbf{P[0, 1]} \\
      \midrule
      \dots\_7\_bm25\_article\_stop670\_porter\_k1\_b0.5 & 0.2368 & 0.5157 \\
      \dots\_10\_bm25\_article\_stop670\_nostem\_k1\_b0.5 & 0.2364 & 0.5634 \\
      \dots\_13\_bm25\_article\_nostop\_porter\_k1\_b0.5 & 0.1924 & 0.4325 \\
      \dots\_16\_bm25\_article\_nostop\_nostem\_k1\_b0.5 & 0.2332 & 0.5537 \\
      \bottomrule
  \end{tabular}
  \caption{Résultats de la méthode BM25}
  \label{tab:result_bm25}
\end{table}

Nous remarquons encore une fois que les runs ayant les meilleurs résultats sont ceux qui ont été réalisés 
avec la racinisation des mots (stemming), et sans l'élimination des mots vides (stopwords).

De plus, en comparaisons avec les résultats obtenus avec la méthode Smart LTN et la méthode Smart LTC, BM25 
a obtenu les meilleurs résultats, avec un score de MaGP de 0.2368 sur la run 7, et un P[0, 1] de 0.5634 sur la run 10.
 
Lors de nos expérimentations, nous avons remarqué que nos meilleurs run ont été réalisés avec des paramètres $\text{k1}$ entre 1 et 1.5 et des paramètres $\text{b}$ entre 0.5 et 0.8.
Nous avons donc décidé de réaliser une grid search pour trouver les meilleurs paramètres :


\begin{table}[!h]
    \begin{minipage}{0.55\linewidth}
        \centering
        \includegraphics[width=1\linewidth]{image.png}
        \label{fig:enter-label}
        \caption{Evolution de MaGP en fonction de k1 et b}
    \end{minipage}%
    \hspace{0.05\linewidth} % Add a 5% width margin
    \begin{minipage}{0.45\linewidth}
        Nous pouvons remarquer que notre score de MaGP est maximisé pour des valeurs de $\text{b}$ 
        assez faible (entre 0.5 et 0.65) et des valeurs de $\text{k1}$ entre 1 et 1.1. \\

        Nous pouvons remarquer très clairement sur le graphique que notre score de MaGP est maximisé avec une valeur de $\text{b}$ 
        égale à 0.5. En effet, sur notre interval de recherche pour $\text{k1}$, nous avons un score élevé et assez stable 
        pour des valeurs de $\text{k1}$ entre 1 et 1.4.
    \end{minipage}
\end{table}

Nous avons également voulu observer si les valeurs de $\text{k1}$ et $\text{b}$ qui maximisent notre score de MaGP
maximisent également notre score de P[0, 1]. 
Voici les résultats obtenus :

\begin{table}[!h]
    \begin{minipage}{0.45\linewidth}
        Nous remarquons tout de suite que les valeurs maximisant notre score de MaGP ne maximisent pas notre score de P[0, 1].
        En effet, nous avons un score de P[0, 1] maximisé pour des valeurs de $\text{b}$ entre 0.65 et 0.75,
        et des valeurs de $\text{k1}$ entre 1.0 et 1.3. \\

        Nous savons donc que les valeurs permettant de maximiser notre score de MaGP ne maximisent pas notre score de P[0, 1].
    \end{minipage}
    \hspace{0.05\linewidth} % Add a 5% width margin
    \begin{minipage}{0.55\linewidth}
        \centering
        \includegraphics[width=1\linewidth]{heatmap_p_bm25.png}
        \label{fig:enter-label}
        \caption{Evolution de P[0, 1] en fonction de k1 et b}
    \end{minipage}%
\end{table}

Méthodes utilisées :
LTN 
LTC
LNU
BM25
BM25F
BM25W
Deep Learning

Explication pour chaque méthode 
paramétrages avec grid search les comparaisons report
correlation entre runs
analyse de la freq des balises presentes dans les runs
ect...


\section{Résultats}
Quelque graph rapel precision recall f1 score ect...
Analyse des résultats

\section{Performances \& Optimisations}

\section{Conclusion}

\section{Annexes}

\end{document} 